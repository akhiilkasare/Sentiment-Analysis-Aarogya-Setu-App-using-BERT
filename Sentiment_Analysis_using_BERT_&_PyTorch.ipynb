{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using BERT & PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Uzl9zMoRxMqRdCR4Y0rxxlvwYy2VPtP3",
      "authorship_tag": "ABX9TyNi3JuqE1tIgtBL+M5+TBS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10ee41241f214245a4880b90f26dea13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_072500071e9643ad9a0818385d91806e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34ebbfb33d9549c79693804ed79ff2e8",
              "IPY_MODEL_2ae4492b69e14adeb01863d3a69655ac"
            ]
          }
        },
        "072500071e9643ad9a0818385d91806e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34ebbfb33d9549c79693804ed79ff2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20e14b670b1848c3b560b6965c0af6aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fd2ea1d12ab4ec98543016b9ef750ae"
          }
        },
        "2ae4492b69e14adeb01863d3a69655ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32ee6b56d44a4b8fae4ec80242735e00",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 746kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc854791c5b743f19234150f9262ac7f"
          }
        },
        "20e14b670b1848c3b560b6965c0af6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fd2ea1d12ab4ec98543016b9ef750ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32ee6b56d44a4b8fae4ec80242735e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc854791c5b743f19234150f9262ac7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb5c28404742467daf5b30106a7bb340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6408b1cb5df746f4843a7533a8ed81ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1274a36953ec4263ba3e1e08fe45b36d",
              "IPY_MODEL_42a95d6e5d8e4b9c8ed965f67cd74165"
            ]
          }
        },
        "6408b1cb5df746f4843a7533a8ed81ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1274a36953ec4263ba3e1e08fe45b36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd36be0668ed418ab637bff2d62dc62d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ebf5225668346b48fbad03d9dba32e8"
          }
        },
        "42a95d6e5d8e4b9c8ed965f67cd74165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a686fae296584a32983598c058056fcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:30&lt;00:00, 14.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b6842ab2dbe492ebb7a903fcc1c5b48"
          }
        },
        "dd36be0668ed418ab637bff2d62dc62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ebf5225668346b48fbad03d9dba32e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a686fae296584a32983598c058056fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b6842ab2dbe492ebb7a903fcc1c5b48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dab436ba23ac40babb8ccf644b9b5c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62ad8288bd1541c3bea4b9a6057e3053",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_326756cd1bea461da68e73cab6c65760",
              "IPY_MODEL_79e9132152724a9a929768a8460c3d12"
            ]
          }
        },
        "62ad8288bd1541c3bea4b9a6057e3053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "326756cd1bea461da68e73cab6c65760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3a267f7e2a1440cb1da8bd99ccd9b12",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa5f4830b6da4ca29f8481295e42ba17"
          }
        },
        "79e9132152724a9a929768a8460c3d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf45c973cfed4775b8099c7ad90777b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:26&lt;00:00, 16.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34550bb0d1d04df3b3133abede4214ef"
          }
        },
        "a3a267f7e2a1440cb1da8bd99ccd9b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa5f4830b6da4ca29f8481295e42ba17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf45c973cfed4775b8099c7ad90777b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34550bb0d1d04df3b3133abede4214ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhiilkasare/Sentiment-Analysis-Aarogya-Setu-App-using-BERT/blob/main/Sentiment_Analysis_using_BERT_%26_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFDpkaYamI2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee935d8-05b0-49ee-ff96-37ea0fdb9f30"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 21.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=085122af95d9c7c5f3a45c4b505b48d5b4c1241d31d55839705cd5b16bf2716b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n",
            "Collecting bert\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/e6/55ed98ef52b168a38192da1aff7265c640f214009790220664ee3b4cb52a/bert-2.2.0.tar.gz\n",
            "Collecting erlastic\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/30/f40d99fe35c38c2e0415b1e746c89569f2483e64ef65d054b9f0f382f234/erlastic-2.0.0.tar.gz\n",
            "Building wheels for collected packages: bert, erlastic\n",
            "  Building wheel for bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert: filename=bert-2.2.0-cp36-none-any.whl size=3756 sha256=09ef5831687c3833dad76cdb801a586c1ff47140af11934642cfc49806a833dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/71/b7/941459453bd38e5d97a8c886361dee19325e9933c9cf88ad46\n",
            "  Building wheel for erlastic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for erlastic: filename=erlastic-2.0.0-cp36-none-any.whl size=6789 sha256=2d95a63215be3f6e41a3a9134f53d0811573f018d43423d40cb3773d1dec0e26\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/62/46/93c713a5f061aeeb4f16eb6bf5ee798816e6ddda70faa78e69\n",
            "Successfully built bert erlastic\n",
            "Installing collected packages: erlastic, bert\n",
            "Successfully installed bert-2.2.0 erlastic-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY6jUe-zF6H5"
      },
      "source": [
        "## Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ljzB3LHsvOg"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "%matplotlib inline \n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 10,6\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acNM7X06F_ZD"
      },
      "source": [
        "## Reading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8nWyYuTyVPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "c441d110-26f8-40f3-a67b-b354e8e35c6a"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Sentiment Analysis Using BERT/reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gp:AOqpTOFdWMJ_oyeoIT_wOSafcZLDc9EquKXZI9YOwOq...</td>\n",
              "      <td>MOHAMMED Ali</td>\n",
              "      <td>https://play-lh.googleusercontent.com/-gAOtym8...</td>\n",
              "      <td>Totally useless app. If it has real time data ...</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-30 20:22:17</td>\n",
              "      <td>The  Aarogya Setu App detects other devices wi...</td>\n",
              "      <td>2020-10-31 04:27:48</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gp:AOqpTOEoCVAknSqa9iSs5AbhL9t0f_8cKmxlFiIRG1H...</td>\n",
              "      <td>Ravi Kumar Reddy Bandi</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Not at all usefull, it isn't a dynamic app whi...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-30 08:28:39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gp:AOqpTOGAU_JskSqjNwAajeOQpGIwDj0z1lFAkZlkMpD...</td>\n",
              "      <td>Ranjan Bharadvaj</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Initially it was worth having it, could see th...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-31 02:25:55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gp:AOqpTOGlLEzm67t1PpjCzwcWLKDwJgS-1fTpJfsnW67...</td>\n",
              "      <td>Pravin's Cuisine</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Totally useless app. If it has real time data ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4245</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-09-12 13:18:18</td>\n",
              "      <td>Thanks for your feedback! We deeply respect yo...</td>\n",
              "      <td>2020-09-12 13:44:14</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gp:AOqpTOHyMTgfF6-a5S8tIY-48AfKKs-2OuhydFlN327...</td>\n",
              "      <td>Johnson P</td>\n",
              "      <td>https://play-lh.googleusercontent.com/-Qd2pEwz...</td>\n",
              "      <td>There is no change in opinion. In fact it is g...</td>\n",
              "      <td>1</td>\n",
              "      <td>313</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-20 17:45:19</td>\n",
              "      <td>We are sorry that we didn't meet your expectat...</td>\n",
              "      <td>2020-07-04 04:51:33</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            reviewId  ...                appId\n",
              "0  gp:AOqpTOFdWMJ_oyeoIT_wOSafcZLDc9EquKXZI9YOwOq...  ...  nic.goi.aarogyasetu\n",
              "1  gp:AOqpTOEoCVAknSqa9iSs5AbhL9t0f_8cKmxlFiIRG1H...  ...  nic.goi.aarogyasetu\n",
              "2  gp:AOqpTOGAU_JskSqjNwAajeOQpGIwDj0z1lFAkZlkMpD...  ...  nic.goi.aarogyasetu\n",
              "3  gp:AOqpTOGlLEzm67t1PpjCzwcWLKDwJgS-1fTpJfsnW67...  ...  nic.goi.aarogyasetu\n",
              "4  gp:AOqpTOHyMTgfF6-a5S8tIY-48AfKKs-2OuhydFlN327...  ...  nic.goi.aarogyasetu\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD9nZs5n0KHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a21c642-5cd2-4426-cae9-6d598582085c"
      },
      "source": [
        "print(\"The shape of the dataset is : \",df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the dataset is :  (1200, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPZUid0GGKS2"
      },
      "source": [
        "## Checking Dataset Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zci7hR1G45dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bea4d12-2bfd-466a-9227-56b88c66d9f2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1200 entries, 0 to 1199\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              1200 non-null   object\n",
            " 1   userName              1200 non-null   object\n",
            " 2   userImage             1200 non-null   object\n",
            " 3   content               1200 non-null   object\n",
            " 4   score                 1200 non-null   int64 \n",
            " 5   thumbsUpCount         1200 non-null   int64 \n",
            " 6   reviewCreatedVersion  1019 non-null   object\n",
            " 7   at                    1200 non-null   object\n",
            " 8   replyContent          1097 non-null   object\n",
            " 9   repliedAt             1097 non-null   object\n",
            " 10  sortOrder             1200 non-null   object\n",
            " 11  appId                 1200 non-null   object\n",
            "dtypes: int64(2), object(10)\n",
            "memory usage: 112.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXPdvGOGPgq"
      },
      "source": [
        "## Checking the score of the reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EGkzJIE48J3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "7aa0e027-3573-44b1-d3fd-abd0e8e4a392"
      },
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('reviews score')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'reviews score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 625,
              "height": 381
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeElZNRx6iDS"
      },
      "source": [
        "* From the above figure we can say that we have pretty much balanced dataset as long as we are talking about positive reviews(1&2) & negative reviews(4&5).\n",
        "\n",
        "* We have double the amount of the neutral reviews or the 3 score.\n",
        "\n",
        "* It's actually great because we are going to group (1&2) into Positive categories, (4&5) into Negative categories and 3 into Neutral categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ovnVBy9M4P"
      },
      "source": [
        "## Grouping the sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT5bMGH55bvi"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating) # converting the rating into integer\n",
        "  if rating <= 2:  # If the rating is less the equal to 2 we are returning 0 which corresponds to `Negative`\n",
        "    return 0\n",
        "  elif rating == 3: # IF the rating is equal to 3 we are returning 1 which corresponds to 'Neutral'\n",
        "    return 1\n",
        "  else: \n",
        "    return 2 # It returns the 2 which corresponds to 'Positive'\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7dP8xXj-ron"
      },
      "source": [
        "## Now we are going to create a new column into our DataFrame  named `sentiments`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B64ZU6E9-p23"
      },
      "source": [
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIaF2zQN_CH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "7713e1d0-82d6-4b81-bba9-4d567c7f3be6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gp:AOqpTOFdWMJ_oyeoIT_wOSafcZLDc9EquKXZI9YOwOq...</td>\n",
              "      <td>MOHAMMED Ali</td>\n",
              "      <td>https://play-lh.googleusercontent.com/-gAOtym8...</td>\n",
              "      <td>Totally useless app. If it has real time data ...</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-30 20:22:17</td>\n",
              "      <td>The  Aarogya Setu App detects other devices wi...</td>\n",
              "      <td>2020-10-31 04:27:48</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gp:AOqpTOEoCVAknSqa9iSs5AbhL9t0f_8cKmxlFiIRG1H...</td>\n",
              "      <td>Ravi Kumar Reddy Bandi</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Not at all usefull, it isn't a dynamic app whi...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-30 08:28:39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gp:AOqpTOGAU_JskSqjNwAajeOQpGIwDj0z1lFAkZlkMpD...</td>\n",
              "      <td>Ranjan Bharadvaj</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Initially it was worth having it, could see th...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-31 02:25:55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gp:AOqpTOGlLEzm67t1PpjCzwcWLKDwJgS-1fTpJfsnW67...</td>\n",
              "      <td>Pravin's Cuisine</td>\n",
              "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
              "      <td>Totally useless app. If it has real time data ...</td>\n",
              "      <td>1</td>\n",
              "      <td>4245</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-09-12 13:18:18</td>\n",
              "      <td>Thanks for your feedback! We deeply respect yo...</td>\n",
              "      <td>2020-09-12 13:44:14</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gp:AOqpTOHyMTgfF6-a5S8tIY-48AfKKs-2OuhydFlN327...</td>\n",
              "      <td>Johnson P</td>\n",
              "      <td>https://play-lh.googleusercontent.com/-Qd2pEwz...</td>\n",
              "      <td>There is no change in opinion. In fact it is g...</td>\n",
              "      <td>1</td>\n",
              "      <td>313</td>\n",
              "      <td>1.4.1</td>\n",
              "      <td>2020-10-20 17:45:19</td>\n",
              "      <td>We are sorry that we didn't meet your expectat...</td>\n",
              "      <td>2020-07-04 04:51:33</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>nic.goi.aarogyasetu</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            reviewId  ... sentiment\n",
              "0  gp:AOqpTOFdWMJ_oyeoIT_wOSafcZLDc9EquKXZI9YOwOq...  ...         0\n",
              "1  gp:AOqpTOEoCVAknSqa9iSs5AbhL9t0f_8cKmxlFiIRG1H...  ...         0\n",
              "2  gp:AOqpTOGAU_JskSqjNwAajeOQpGIwDj0z1lFAkZlkMpD...  ...         0\n",
              "3  gp:AOqpTOGlLEzm67t1PpjCzwcWLKDwJgS-1fTpJfsnW67...  ...         0\n",
              "4  gp:AOqpTOHyMTgfF6-a5S8tIY-48AfKKs-2OuhydFlN327...  ...         0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIFjslUiAg1L"
      },
      "source": [
        "## Setting the class names and visualizing the count of the reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsGTgU8o_Daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "7dd472dd-9904-4c12-a958-de48489d6466"
      },
      "source": [
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel(\"Reviews Sentiments\")\n",
        "ax.set_xticklabels(class_names);"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABOIAAAL6CAYAAACb0/mKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdbZCW1Z0n/m83TdM8tQ0OMkMRFCIhQmJISUxpHERtJyUzZFYTCLKOpYKomSxGzFbJTmWTmBlxMxOXJO6iQonJGoZVI7VgsiYRH9CoWcE0ZmwlipCgONg82eGhadru/wuL/tPSzZP0TXPz+bw6933O+V3nbqqusr6e6zolLS0tLQEAAAAAOlXpsV4AAAAAAJwIBHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABRA2bFeAJ2ntrY2u3fvTrdu3dKjR49jvRwAAACA497u3bvz3nvvpUePHhk5cuRhzRXEFbHdu3enubk5zc3N2bNnz7FeDgAAAEDR2L1792HPEcQVsW7duqW5uTmlpaXp1avXsV4OAAAAwHFv586daW5uTrdu3Q57riCuiPXo0SN79uxJr169MmLEiGO9HAAAAIDj3urVq7N9+/Yjeg2YwxoAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAGXHegGFtGXLllxyySXZtm1bkuTSSy/N7bff3uH4pqamLFq0KEuXLs3atWvT2NiYQYMGpbq6OldddVX69+9/SNe877778thjj2XDhg0pLy/P0KFDM2HChEyePDllZSfUPwEAAADACeuESoFuu+221hDuYP70pz9l6tSpWbVqVZvv16xZkzVr1uThhx/OvHnzcsYZZ3RYo7a2NtOnT09dXV3rd7t27UpNTU1qamqydOnSzJ8/P3379j2yHwQAAADAceOEeTT1mWeeydKlS/ORj3zkkMbPnDkzq1atSklJSa6//vr86le/ytNPP53Zs2enb9++qaury3XXXddhsLdt27Zcf/31qaurS2VlZWbPnp2nn346v/rVr3L99denpKQkNTU1mTlz5tH8mQAAAAB0USdEELdr165861vfSpJ84xvfOOj4p556KsuXL0+S3HjjjbnpppsyZMiQnHLKKbnsssty1113paSkJBs3bsz8+fPbrTFv3rxs3LgxJSUlmTt3bi677LKccsopGTJkSG666abceOONSZLly5e3XgsAAACA4nVCBHE//OEPs379+nz+85/P+eeff9DxCxcuTJL069cvU6dO3a9/zJgxGTduXJLkwQcfTFNTU5v+pqamPPDAA0mScePGZcyYMfvVmDp1aqqqqtpcDwAAAIDiVfRB3CuvvJIf/ehH6d27d/7hH/7hoOMbGhry3HPPJUkuuuiilJeXtzvukksuSfL+I6grV65s07dixYrU19e3GfdB5eXlqa6uTpI8++yzaWhoOLQfBAAAAMBxqaiDuObm5nzjG99IU1NTbrzxxgwcOPCgc1577bXs3r07STJ69OgOx+3b9/LLL7fp2/fzodTYvXt3Xn/99YOuDQAAAIDjV1EHcT/+8Y/zu9/9LqNGjcoVV1xxSHPWrl3b2h48eHCH4wYNGpTS0tL95uz7ubS0NIMGDeqwxr71P1gDAAAAgOJStEHchg0b8v3vfz+lpaX51re+lW7duh3SvK1bt7a2Tz755A7Hde/ePZWVlUmy38mpe2tUVlame/fuHdbo379/a7uj01cBAAAAKA5lx3oBneXWW2/Nzp07M2XKlJx55pmHPG/Xrl2t7R49ehxw7N7+nTt3tlvjYPMrKipa2x+scTRt3759v/fYHStnnXXWsV4CwEF1lXtmV+Z+DhwP3M8Pzv0cOB4U0/28KHfE/fznP88TTzyRAQMGZObMmcd6OQAAAABQfDvi6uvrc9tttyVJbrnllvTt2/ew5vfs2bO1vffQho7s7e/Vq1e7NQ42f9+TUj9Y42jq06dPRowY0Wn1j8Swxd6JB3Q9b1w6NIndAYdj3XNDj/USAPZz2jnv/7em+/mhW/dN93Og6znt213zfr569eps3779iOYW3Y64O++8M3V1dfnc5z6Xv/mbvzns+f369Wttb968ucNxe/bsSX19fZKkqqqq3Rr19fVpamrqsMaWLVta2x+sAQAAAEBxKbodcW+++WaS5Ne//vVBd4EtXrw4ixcvTpL8j//xP1JdXZ2hQ////xO0t1Z7NmzYkObm5iRpM2ffz83NzXnrrbdy6qmnHnCt7dUAAAAAoLgU3Y64D2v48OGthyysWrWqw3E1NTWt7VGjRrXp2/fzodTo0aNHTj/99CNaLwAAAADHh6LbETdr1qz8p//0nw445j/8h/+QJLngggty4403JkkGDx6c5P2TTM8555w8+eSTWbZsWf7rf/2vKS8v36/Go48+muT9R0o/+KzymDFjUllZmfr6+jz66KP5whe+sN/8xsbGPP7440mSc889t80JqgAAAAAUn6IL4j7ykY8c8tiqqqqcccYZ+30/ZcqUPPnkk9myZUsWLFiQ6667rk3/ypUr8+STTyZJJk6cmLKytn/GsrKyTJo0KfPnz88TTzyRlStX7hfWLViwoPUdcVOmTDnkNQMAAABwfPJoajvOP//8jB07NkkyZ86czJkzJ+vXr09dXV0WL16cG264Ic3NzRk4cGCmTZvWbo1rr702AwcOTHNzc2644YYsXrw4dXV1Wb9+ff77f//vmTNnTpJk7NixrdcCAAAAoHgV3Y64o+V73/tepk2bllWrVmXu3LmZO3dum/4BAwbk7rvv7vC006qqqtx1112ZPn166urqcsstt+w3ZvTo0bnjjjs6Zf0AAAAAdC2CuA5UVlZm4cKFWbRoUZYsWZK1a9dmz549GTRoUC666KJcffXV6d+//wFrjBw5MkuWLMmCBQuybNmybNiwId27d8+wYcMyYcKETJ48eb/HWgEAAAAoTidkCrR69epDGldWVpYrrrgiV1xxxRFfq3///rn55ptz8803H3ENAAAAAI5/3hEHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAUgiAMAAACAAhDEAQAAAEABCOIAAAAAoAAEcQAAAABQAII4AAAAACgAQRwAAAAAFIAgDgAAAAAKQBAHAAAAAAVQdqwXcLS9/fbbefzxx/Nv//ZvWb16dTZv3pwtW7akW7duGThwYD796U/nS1/6UsaMGdNhjYcffjizZs066LWGDx+eRx555IBjtmzZkvvuuy+PPfZYNmzYkPLy8gwdOjQTJkzI5MmTU1ZWdP8EAAAAALSj6FKgZcuW5Tvf+U67fevWrcu6deuyePHiTJw4Md/+9rfTrVu3TltLbW1tpk+fnrq6utbvdu3alZqamtTU1GTp0qWZP39++vbt22lrAAAAAKBrKLogrkePHjn//PPz2c9+NiNHjswpp5yS/v37Z+vWramtrc38+fPzyiuv5MEHH0xVVVW+/vWvH7Deiy++2GHfgUK8bdu25frrr09dXV0qKysza9asnHfeeWloaMhPf/rT3H333ampqcnMmTMzb968I/69AAAAABwfii6ImzhxYiZOnLjf9/369cuwYcPyV3/1V/nyl7+c2tra3H///fn7v//79OzZs8N6vXv3PqJ1zJs3Lxs3bkxJSUnmzp3b5lHYm266KRUVFZkzZ06WL1+e5cuXZ+zYsUd0HQAAAACODyfcYQ3l5eX5whe+kOT9x0TXrFlz1K/R1NSUBx54IEkybty4dt9HN3Xq1FRVVSVJFi5ceNTXAAAAAEDXcsIFcUnaHJBQXl5+1OuvWLEi9fX1SZJLLrmk3THl5eWprq5Okjz77LNpaGg46usAAAAAoOs44YK45ubm/OIXv0iSVFZW5rTTTjukeY2NjYd8jZdffrm1PXr06A7H7e3bvXt3Xn/99UOuDwAAAMDxp+jeEdeelpaWbN68OatXr878+fPzwgsvJElmzJhx0B1xl156aV577bXs2bMnvXr1ysiRI3PxxRdn0qRJ6dWrV7tz1q5dmyQpLS3NoEGDOqw9ePDgNnM+8YlPHO5PAwAAAOA4UdRB3IwZM1p3v+3r5JNPzowZMzJ58uSD1qitrW1t79y5MytWrMiKFSty//33584778zHP/7x/eZs3bo1yfs77rp3795h7f79+7e2t23bdtC1AAAAAHD8Kuogrj3l5eW5/PLLc8EFF3Q4pqKiIpdeemmqq6vz0Y9+NH/+53+e9957L6+++moWLlyYn/3sZ1m/fn2mTp2ahx9+OAMHDmwzf9euXUmSHj16HHAtFRUVre2dO3d+iF91YNu3b8/KlSs7rf7hOOuss471EgAOqqvcM7sy93PgeOB+fnDu58DxoJju50X9jrh//ud/zosvvpiVK1dm2bJl+e53v5shQ4bkzjvvzN/+7d/mxRdfbHfe+PHjc/vtt6e6ujpDhw5Nz54906dPn4wZMyZ33HFHZs2alSTZtGlT5syZU8ifBAAAAMBxqqh3xPXo0aN1V1qfPn0yePDgfP7zn8+VV16ZVatW5Stf+Up++ctfprKy8rDqXnXVVfnZz36Wl156KY8++mhuvfXWNo+g9uzZM8n7hzAcyL4npXb0vrmjoU+fPhkxYkSn1QcoNnYHABQH93OA4tDV7uerV6/O9u3bj2huUe+Ia09FRUVuvvnmJO+/y+3nP//5EdW58MILk7z/SOkf/vCHNn39+vVLktTX16epqanDGlu2bGltV1VVHdE6AAAAADg+nHBBXJJ86lOfam2vXr36iGqcfPLJre36+vo2fUOHDk2SNDc356233uqwxptvvrnfHAAAAACK0wkZxO27S62kpOSIatTV1bW2P/ho66hRo1rbq1at6rBGTU1NkvcfoT399NOPaB0AAAAAHB9OyCBuxYoVre0hQ4YcUY1ly5YlSXr37p1TTz21Td+YMWNaw7lHH3203fmNjY15/PHHkyTnnntumxNUAQAAACg+RRfErVmz5oD97777bv7lX/4lSdKtW7fWd73ttX379oO+cO+ee+7Jyy+/nCS55JJL2hzUkCRlZWWZNGlSkuSJJ55o95jdBQsWtL4jbsqUKQe8HgAAAADHv6I7NXXChAm54IILcvHFF2fUqFE5+eSTU1pamnfeeSfPP/987r333rz99ttJkmuuuWa/HXHr16/PlVdemfHjx2fs2LEZPnx4TjrppDQ2NubVV1/Nv/7rv7buhhswYEBmzJjR7jquvfbaLF26NBs3bswNN9yQWbNm5bzzzktDQ0Meeuih3HPPPUmSsWPHZuzYsZ34FwEAAACgKyi6IO69997LY489lscee6zDMd26dcu0adNy0003tdtfX1+fRYsWZdGiRR3WOP300/P9738/AwcObLe/qqoqd911V6ZPn566urrccsst+40ZPXp07rjjjoP8IgAAAACKQdEFcT/5yU/y/PPPZ8WKFXnrrbeyefPmNDY2pk+fPjnttNPymc98JpdddlmHp5QOGTIk//iP/5iamprU1tZm06ZN2bZtW0pLS9O/f/+MGjUq1dXVGT9+fMrLyw+4lpEjR2bJkiVZsGBBli1blg0bNqR79+4ZNmxYJkyYkMmTJ6esrOj+CQAAAABoR0lLS0vLsV4EnWP16tXZvn17+vTpkxEjRhzr5bQxbPHaY70EgP28cWn7/5OGjq17zt8M6HpOO8d/ax6udd90Pwe6ntO+3TXv5x8mbym6wxoAAAAAoCsSxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIoO9YLONrefvvtPP744/m3f/u3rF69Ops3b86WLVvSrVu3DBw4MJ/+9KfzpS99KWPGjDloraampixatChLly7N2rVr09jYmEGDBqW6ujpXXXVV+vfvf9AaW7ZsyX333ZfHHnssGzZsSHl5eYYOHZoJEyZk8uTJKSsrun8CAAAAANpRdCnQsmXL8p3vfKfdvnXr1mXdunVZvHhxJk6cmG9/+9vp1q1bu2P/9Kc/ZerUqVm1alWb79esWZM1a9bk4Ycfzrx583LGGWd0uJba2tpMnz49dXV1rd/t2rUrNTU1qampydKlSzN//vz07dv3CH4pAAAAAMeTogvievTokfPPPz+f/exnM3LkyJxyyinp379/tm7dmtra2syfPz+vvPJKHnzwwVRVVeXrX/96u3VmzpyZVatWpaSkJNddd12++MUvpqKiIs8880xuu+221NXV5brrrsuSJUtSVVW13/xt27bl+uuvT11dXSorKzNr1qycd955aWhoyE9/+tPcfffdqampycyZMzNv3rzO/rMAAAAAcIwVXRA3ceLETJw4cb/v+/Xrl2HDhuWv/uqv8uUvfzm1tbW5//778/d///fp2bNnm7FPPfVUli9fniS58cYbc8MNN7T2XXbZZRkyZEiuuOKKbNy4MfPnz283zJs3b142btyYkpKSzJ07t82jsDfddFMqKioyZ86cLF++PMuXL8/YsWOP1p8AAAAAgC7ohDusoby8PF/4wheSvP+Y6Jo1a/Ybs3DhwiTvh3dTp07dr3/MmDEZN25ckuTBBx9MU1NTm/6mpqY88MADSZJx48a1+z66qVOntu6k23s9AAAAAIrXCRfEJWlzQEJ5eXmbvoaGhjz33HNJkosuumi//r0uueSSJO8/grpy5co2fStWrEh9fX2bcR9UXl6e6urqJMmzzz6bhoaGI/glAAAAABwvTrggrrm5Ob/4xS+SJJWVlTnttNPa9L/22mvZvXt3kmT06NEd1tm37+WXX27Tt+/nQ6mxe/fuvP7664f2AwAAAAA4Lp0QQVxLS0s2bdqUX//615k6dWpeeOGFJMmMGTP22/G2du3a1vbgwYM7rDlo0KCUlpbuN2ffz6WlpRk0aFCHNfat/8EaAAAAABSXojusYV8zZsxo3f22r5NPPjkzZszI5MmT9+vbunVrm3Ed6d69eyorK7Nt27Zs27at3RqVlZXp3r17hzX69+/f2v5gDQAAAACKS1EHce0pLy/P5ZdfngsuuKDd/l27drW2e/ToccBae/t37tzZbo2Dza+oqGhtf7DG0bR9+/b93mN3rJx11lnHegkAB9VV7pldmfs5cDxwPz8493PgeFBM9/OifjT1n//5n/Piiy9m5cqVWbZsWb773e9myJAhufPOO/O3f/u3efHFF4/1EgEAAAA4QRT1jrgePXq07krr06dPBg8enM9//vO58sors2rVqnzlK1/JL3/5y1RWVrbO6dmzZ2t776ENHdnb36tXrzbf761xsPn7npT6wRpHU58+fTJixIhOqw9QbOwOACgO7ucAxaGr3c9Xr16d7du3H9Hcot4R156KiorcfPPNSd5/l9vPf/7zNv39+vVrbW/evLnDOnv27El9fX2SpKqqqt0a9fX1aWpq6rDGli1bWtsfrAEAAABAcTnhgrgk+dSnPtXaXr16dZu+oUOHtrbffPPNDmts2LAhzc3N+83Z93Nzc3PeeuutDmvsW/+DNQAAAAAoLidkELfvLrWSkpI2fcOHD299nHXVqlUd1qipqWltjxo1qk3fvp8PpUaPHj1y+umnH8LKAQAAADhenZBB3IoVK1rbQ4YMadNXUVGRc845J0mybNmyNDY2tlvj0UcfTfL+I6UffFZ5zJgxre+d2zvugxobG/P4448nSc4999w2J6gCAAAAUHyKLohbs2bNAfvffffd/Mu//EuSpFu3brnwwgv3GzNlypQk77/DbcGCBfv1r1y5Mk8++WSSZOLEiSkra3vmRVlZWSZNmpQkeeKJJ9o9ZnfBggWt74jbez0AAAAAilfRnZo6YcKEXHDBBbn44oszatSonHzyySktLc0777yT559/Pvfee2/efvvtJMk111yz3464JDn//PMzduzYLF++PHPmzMmuXbvyxS9+MRUVFXnmmWcye/bsNDc3Z+DAgZk2bVq767j22muzdOnSbNy4MTfccENmzZqV8847Lw0NDXnooYdyzz33JEnGjh2bsWPHdt4fBAAAAIAuoaSlpaXlWC/iaBoxYsRBx3Tr1i3Tpk3LTTfdtN874vaqr6/PtGnTOnzH24ABAzJv3rycccYZHV6ntrY206dPT11dXbv9o0ePzvz589O3b9+DrvlI7D1Ot0+fPof0dymkYYvXHuslAOznjUsdnHO41j3nbwZ0Paed4781D9e6b7qfA13Pad/umvfzD5O3FN2OuJ/85Cd5/vnns2LFirz11lvZvHlzGhsb06dPn5x22mn5zGc+k8suu+ygp5RWVlZm4cKFWbRoUZYsWZK1a9dmz549GTRoUC666KJcffXV6d+//wFrjBw5MkuWLMmCBQuybNmybNiwId27d8+wYcMyYcKETJ48eb/HWgEAAAAoTkW3I47/nx1xAIfHjrjDZ0cc0BXZEXf47IgDuqJi3BFXdIc1AAAAAEBXJIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACkAQBwAAAAAFIIgDAAAAgAIQxAEAAABAAQjiAAAAAKAABHEAAAAAUACCOAAAAAAoAEEcAAAAABSAIA4AAAAACqDsWC+gM+zevTtPP/10nnnmmbz00ktZv359du7cmT59+mT48OG58MILM2nSpPTp06fd+Q8//HBmzZp10OsMHz48jzzyyAHHbNmyJffdd18ee+yxbNiwIeXl5Rk6dGgmTJiQyZMnp6ysKP8JAAAAAPiAokyBzjnnnOzYsWO/77dt25YXXnghL7zwQn70ox/lhz/8Yc4888xOW0dtbW2mT5+eurq61u927dqVmpqa1NTUZOnSpZk/f3769u3baWsAAAAAoGsoyiBux44d6d69e6qrq1NdXZ1PfvKTqaqqyjvvvJMlS5bk3nvvzb//+79n2rRpWbp0aQYOHNhhrRdffLHDvm7dunXYt23btlx//fWpq6tLZWVlZs2alfPOOy8NDQ356U9/mrvvvjs1NTWZOXNm5s2b96F+LwAAAABdX1EGcVOmTMlXvvKVDBgwoM33J510Um6++eZ87GMfy9e//vW8++67mTt3br71rW91WKt3795HtIZ58+Zl48aNKSkpydy5czNmzJjWvptuuikVFRWZM2dOli9fnuXLl2fs2LFHdB0AAAAAjg9FeVjDN7/5zf1CuH1NmDAhH/vYx5Iky5cvP+rXb2pqygMPPJAkGTduXJsQbq+pU6emqqoqSbJw4cKjvgYAAAAAupaiDOIOxfDhw5Mk77zzzlGvvWLFitTX1ydJLrnkknbHlJeXp7q6Okny7LPPpqGh4aivAwAAAICu44QN4jZt2pQkh3xQQmNj4yHXfvnll1vbo0eP7nDc3r7du3fn9ddfP+T6AAAAABx/ivIdcQezadOm1kMYPv3pTx9w7KWXXprXXnste/bsSa9evTJy5MhcfPHFmTRpUnr16tXunLVr1yZJSnuHVwEAACAASURBVEtLM2jQoA5rDx48uM2cT3ziE4f7UwAAAAA4TpyQO+K+973vZc+ePUmSyy+//IBja2trW8fu3LkzK1asyOzZs/OFL3whr776artztm7dmiSprKxM9+7dO6zdv3//1va2bdsO6zcAAAAAcHw54XbELVmyJA8//HCS5MILL8xf/uVf7jemoqIil156aaqrq/PRj340f/7nf5733nsvr776ahYuXJif/exnWb9+faZOnZqHH344AwcObDN/165dSZIePXoccC0VFRWt7Z07d37Yn9ah7du3Z+XKlZ1W/3CcddZZx3oJAAfVVe6ZXZn7OXA8cD8/OPdz4HhQTPfzEyqIe+mll/KNb3wjSfIXf/EX+ad/+qd2x40fPz7jx4/f7/sxY8ZkzJgxOfPMMzN79uxs2rQpc+bMyezZszt13QAAAAAc/06YIO6NN97I9OnT09DQkKqqqsyfP7/No6GH46qrrsrPfvazvPTSS3n00Udz6623tnkEtWfPnkneP4ThQPY9KbWj980dDX369MmIESM6rT5AsbE7AKA4uJ8DFIeudj9fvXp1tm/ffkRzT4h3xG3YsCHXXHNNtm7dmt69e2fevHk5/fTTP1TNCy+8MMn7j5T+4Q9/aNPXr1+/JEl9fX2ampo6rLFly5bWdlVV1YdaDwAAAABdW9EHcZs2bcrVV1+dt99+OxUVFbnrrrty5plnfui6J598cmu7vr6+Td/QoUOTJM3NzXnrrbc6rPHmm2/uNwcAAACA4lTUQdy7776bq6++OuvWrUv37t3zgx/8IGefffZRqV1XV9farqysbNM3atSo1vaqVas6rFFTU5Pk/UMdPuwOPQAAAAC6tqIN4nbs2JFp06bl97//fUpLS/Pd7343559//lGrv2zZsiRJ7969c+qpp7bpGzNmTGs49+ijj7Y7v7GxMY8//niS5Nxzz21zgioAAAAAxacog7jGxsbccMMNeemll5Ikt956a7unoLZn+/btB33h3j333JOXX345SXLJJZe0OaghScrKyjJp0qQkyRNPPNHuMbsLFixofUfclClTDmltAAAAABy/iu7U1Pfeey9f+9rX8pvf/CZJMmPGjIwfPz47duzocE6vXr1SUlKSJFm/fn2uvPLKjB8/PmPHjs3w4cNz0kknpbGxMa+++mr+9V//tXU33IABAzJjxox2a1577bVZunRpNm7cmBtuuCGzZs3Keeedl4aGhjz00EO55557kiRjx47N2LFjj+afAAAAAIAuqOiCuLfffrs1KEuSH/zgB/nBD35wwDnLli3L4MGDWz/X19dn0aJFWbRoUYdzTj/99Hz/+9/PwIED2+2vqqrKXXfdlenTp6euri633HLLfmNGjx6dO+6442A/CQAAAIAiUHRB3Ic1ZMiQ/OM//mNqampSW1ubTZs2Zdu2bSktLU3//v0zatSoVFdXZ/z48SkvLz9grZEjR2bJkiVZsGBBli1blg0bNqR79+4ZNmxYJkyYkMmTJ6eszD8BAAAAwImg6FKgwYMHZ/Xq1Uc8v3fv3pk4cWImTpx4VNbTv3//3Hzzzbn55puPSj0AAAAAjk9FeVgDAAAAAHQ1gjgAAAAAKABBHAAAAAAUgCAOAAAAAApAEAcAAAAABSCIAwAAAIACEMQBAAAAQAEI4gAAAACgAARxAAAAAFAAgjgAAAAAKABBHAAAAAAUgCAOAAAAAApAEAcAAAAABSCIAwAAAIACKOuMorNmzUpJSUm+9rWv5ZRTTjmkOXV1dbnjjjtSUlKS2267rTOWBQAAAADHTKfsiFu8eHEWL16c+vr6Q57zpz/9qXUeAAAAABQbj6YCAAAAQAF0mSCuqakpSVJW1ilPywIAAADAMdVlgrjXX389SXLSSScd45UAAAAAwNF3VLafvfDCC+1+/7vf/S5bt2494NzGxsasW7cu8+fPT0lJST7+8Y8fjSUBAAAAQJdyVIK4v/u7v0tJSUmb71paWvJf/st/OeQaLS0tKSkpyWWXXXY0lgQAAAAAXcpReyFbS0vLIX3XkZ49e2bq1KkZP3780VoSAAAAAHQZRyWImz17dpvPs2bNSklJSW688cYMHDiww3klJSXp0aNHTjnllIwcOTI9e/Y8GssBAAAAgC7nqARxl156aZvPs2bNSpJUV1fn9NNPPxqXAAAAAIDj2lF7NHVfP/7xj5MkgwcP7ozyAAAAAHDc6ZQg7uyzz+6MsgAAAABw3Co91gsAAAAAgBNBp+yI29e2bdtSU1OT9evXZ/v27XnvvfcOOuerX/1qZy8LAAAAAAqq04K4d999N7fffnseeeSRNDU1HdZcQRwAAAAAxaZTgrgdO3bkiiuuyOuvv56WlpbDmltSUtIZSwIAAACAY6pTgrh77703r732WpLk9NNPz3/8j/8xn/zkJ3PSSSeltNRr6QAAAAA48XRKEPfLX/4yJSUlOfPMM/PjH/84PXr06IzLAAAAAMBxo1O2p7355ptJkmnTpgnhAAAAACCdFMR17949SfKRj3ykM8oDAAAAwHGnU4K4U089NUmyZcuWzigPAAAAAMedTgniJkyYkJaWljz++OOdUR4AAAAAjjudEsRNmTIlo0aNyv/+3/87zz//fGdcAgAAAACOK50SxJWVlWXevHn55Cc/mWnTpuW//bf/ltra2jQ0NHTG5QAAAACgyyvrjKJnnHFGa7ulpSX33Xdf7rvvvkOaW1JSktra2s5YFgAAAAAcM50SxLW0tBzwMwAAAACcaDoliLv00ks7oywAAAAAHLc6JYibPXt2Z5QFAAAAgONWpxzWAAAAAAC0JYgDAAAAgAIQxAEAAABAAXTKO+I2bNjwoeYPGjToKK0EAAAAALqGTgniLrzwwpSUlBzR3JKSktTW1h7lFQEAAADAsdUpQVyStLS0dFZpAAAAADjudEoQ99WvfvWgY3bu3Jk33ngjzz77bPbs2ZPRo0fnc5/7XGcsBwAAAACOuWMWxO1VV1eXW265Jc8//3wuu+yyTJw4sTOWBAAAAADH1DE/NXXAgAGZO3duhg0blltvvTWvvPLKsV4SAAAAABx1xzyIS5Ly8vJceeWV2bNnT+67775jvRwAAAAAOOq6RBCXJB//+MeTJL/5zW+O8UoAAAAA4OjrMkFcc3NzkmTz5s3HeCUAAAAAcPR1mSBu+fLlSZK+ffse45UAAAAAwNHXJYK4//N//k/mzZuXkpKSjB49+lgvBwAAAACOurLOKDpr1qyDjmlpacm7776bl19+OXV1dWlpaUlpaWmuueaazlgSAAAAABxTnRLELV68OCUlJYc0tqWl5f2FlJXlH/7hHzJmzJgPff3du3fn6aefzjPPPJOXXnop69evz86dO9OnT58MHz48F154YSZNmpQ+ffocsE5TU1MWLVqUpUuXZu3atWlsbMygQYNSXV2dq666Kv379z/oWrZs2ZL77rsvjz32WDZs2JDy8vIMHTo0EyZMyOTJk1NW1in/BAAAAAB0MZ2WAu0N2DpSWlqa3r175yMf+UjOPvvsfPnLX87QoUOPyrXPOeec7NixY7/vt23blhdeeCEvvPBCfvSjH+WHP/xhzjzzzHZr/OlPf8rUqVOzatWqNt+vWbMma9asycMPP5x58+bljDPO6HAdtbW1mT59eurq6lq/27VrV2pqalJTU5OlS5dm/vz53osHAAAAcALolCDu1Vdf7Yyyh2zHjh3p3r17qqurU11dnU9+8pOpqqrKO++8kyVLluTee+/Nv//7v2fatGlZunRpBg4cuF+NmTNnZtWqVSkpKcl1112XL37xi6moqMgzzzyT2267LXV1dbnuuuuyZMmSVFVV7Td/27Ztuf7661NXV5fKysrMmjUr5513XhoaGvLTn/40d999d2pqajJz5szMmzevEH8WAAAAAI6hLnFYw9E2ZcqUPPHEE5kzZ07+5m/+JqeeempOOumkDB8+PDfffHNuv/32JMm7776buXPn7jf/qaeeaj3F9cYbb8xNN92UIUOG5JRTTslll12Wu+66KyUlJdm4cWPmz5/f7hrmzZuXjRs3pqSkJHPnzs1ll12WU045JUOGDMlNN92UG2+8Mcn7p8XuvRYAAAAAxasog7hvfvObGTBgQIf9EyZMyMc+9rEkaTcEW7hwYZKkX79+mTp16n79Y8aMybhx45IkDz74YJqamtr0NzU15YEHHkiSjBs3rt333k2dOrV1J93e6wEAAABQvIoyiDsUw4cPT5K88847bb5vaGjIc889lyS56KKLUl5e3u78Sy65JMn7j6CuXLmyTd+KFStSX1/fZtwHlZeXp7q6Okny7LPPpqGh4Qh/CQAAAADHg04/srOlpSWPP/54fv3rX2f16tXZtm1bkqSqqiof//jH87nPfS4XXHDBIZ+yerRs2rQpSfY7KOG1117L7t27kySjR4/ucP6+fS+//HI++9nPtvnc3rj2ajz00EPZvXt3Xn/99XziE584vB8BAAAAwHGjU4O4F198MbNmzcof//jH1u/2nqZaUlKSF198MQsXLsyQIUNy++2359Of/nRnLqfVpk2b8uKLLybJftdcu3Zta3vw4MEd1hg0aFBKS0vT3NzcZs6+NUpLSzNo0KAOa+xbf+3atYI4AAAAgCLWaY+mPvXUU7nyyivzxz/+MS0tLWlpaUmPHj0yaNCgDBo0KBUVFa3f/+EPf8jf/d3f5emnn+6s5bTxve99L3v27EmSXH755W36tm7d2to++eSTO6zRvXv3VFZWJknrLr8P1qisrEz37t07rNG/f//W9gdrAAAAAFBcOmVH3NatW3PzzTenqakppaWl+dKXvpTLL788Z5xxRusjqC0tLXnllVeyaNGiPPTQQ2lqasrMmTPzq1/9qvUQg86wZMmSPPzww0mSCy+8MH/5l3/Zpn/Xrl2t7R49ehyw1t7+nTt3tlvjYPMrKipa2x+scTRt3759v/fYHStnnXXWsV4CwEF1lXtmV+Z+DhwP3M8Pzv0cOB4U0/28U3bE3X///dm+fXvKyspy55135jvf+U5GjhzZ5j1wJSUlGTlyZG699db8z//5P9OtW7ds3749999/f2csKUny0ksv5Rvf+EaS5C/+4i/yT//0T512LQAAAADYV6fsiHvqqadSUlKSSZMm5cILLzzo+HHjxuXLX/5yFi5cmKeeeipf/epXj/qa3njjjUyfPj0NDQ2pqqrK/Pnz2zwaulfPnj1b23sPbejI3v5evXq1W+Ng8/c9KfWDNY6mPn36ZMSIEZ1WH6DY2B0AUBzczwGKQ1e7n69evTrbt28/ormdsiNu/fr1SZKLL774kOfsHbvvwQ5Hy4YNG3LNNddk69at6d27d+bNm5fTTz+93bH9+vVrbW/evLnDmnv27El9fX2S7Pco7d4a9fX1aWpq6rDGli1bWtud+TguAAAAAMdepwRxe993dtJJJx3ynL0HHxztd6Vt2rQpV199dd5+++1UVFTkrrvuyplnntnh+KFDh7a233zzzQ7HbdiwIc3NzfvN2fdzc3Nz3nrrrQ5r7Fv/gzUAAAAAKC6dEsTt3d21du3aQ56zbt26JG13pH1Y7777bq6++uqsW7cu3bt3zw9+8IOcffbZB5wzfPjw1kMWVq1a1eG4mpqa1vaoUaPa9O37+VBq9OjRo8MdegAAAAAUh04J4kaNGpWWlpb85Cc/OeQ5999/f+sBDkfDjh07Mm3atPz+979PaWlpvvvd7+b8888/6LyKioqcc845SZJly5alsbGx3XGPPvpokvdDxw8+qzxmzJjWHX57x31QY2NjHn/88STJueee2+YEVQAAAACKT6cEcePHj0+S/Pa3v81//s//+YCPm+7atSu33HJLfvvb3yZJ/vqv//pDX7+xsTE33HBDXnrppSTJrbfe2rqmQzFlypQk77/DbcGCBfv1r1y5Mk8++WSSZOLEiSkra3vmRVlZWSZNmpQkeeKJJ9o9ZnfBggWt74jbez0AAAAAilennJo6YcKE/K//9b/yu9/9Lo888kiee+65/PVf/3VGjx6dAQMGJEnq6uqyatWqPPLII62HIpx55pmZMGHCh7r2e++9l6997Wv5zW9+kySZMWNGxo8fnx07dnQ4p1evXikpKWn9fP7552fs2LFZvnx55syZk127duWLX/xiKioq8swzz2T27Nlpbm7OwIEDM23atHZrXnvttVm6dGk2btyYG264IbNmzcp5552XhoaGPPTQQ7nnnnuSJGPHjs3YsWM/1G8GAAAAoOsraWlpaemMwps3b85VV12V11577f0L7RN07Wvv5YcPH54f/ehH6d+//4e67ptvvpmLLrrosOYsW7YsgwcPbvNdfX19pk2b1uE73gYMGJB58+bljDPO6LBubW1tpk+fnrq6unb7R48enfnz56dv376Htd5Dtfc43T59+mTEiBGdco0jNWzxob8/EKBQ3rjUwTmHa91z/mZA13PaOf5b83Ct+6b7OdD1nPbtrnk//zB5S6fsiEuSk08+OQ899FDmzp2bRYsWZdu2be2O69evXy6//PJcf/31KS8v76zlHLbKysosXLgwixYtypIlS7J27drs2bMngwYNykUXXZSrr776oKHhyJEjs2TJkixYsCDLli3Lhg0b0r179wwbNiwTJkzI5MmT93usFQAAAIDi1Gk74vbV1NSUl19+Ob///e+zdevWJO8HcCNGjMjIkSOFUZ3EjjiAw2NH3OGzIw7oiuyIO3x2xAFdkR1xR6isrCyf+tSn8qlPfaoQlwMAAACALqfTgrjt27cnSXr27Jlu3bodcOx7772XXbt2JUn69OnTWUsCAAAAgGOmtDOK/r//9//ymc98Jp/73OdaH0U9kK1bt+bcc8/N2WefnZqams5YEgAAAAAcU50SxP3iF79IS0tLxo0blz/7sz876Pg/+7M/ywUXXJDm5ub83//7fztjSQAAAABwTHVKEPfb3/42JSUlOe+88w55ztixY5MkK1as6IwlAQAAAMAx1SlB3B//+MckyUc/+tFDnjNs2LAkyZtvvtkZSwIAAACAY6pTgriGhoYkSa9evQ55Ts+ePZMkO3bs6IwlAQAAAMAx1SlBXN++fZMkdXV1hzxn06ZNSZLevXt3xpIAAADg/2Pvv6OsrA798f89lAEFaQoiltiJklgxinLRIDFiQSXRj9eI0WCPxpqo39xcE2OCufmYjy4TC+olxtgj5oLYIqhoxKgomKBgQ6UIDtKkyAzC7w9+cy4DMzSZZxBfr7Vm+czscvYZlvuceZ/97A3QoOoliNtuu+2SJKNGjVrjNn//+9+TJFtvvXV9DAkAAAAAGlS9BHEHHHBAli5dmvvuuy8ffvjhautPmTIl999/f8rKytKtW7f6GBIAAAAANKh6CeJOPPHENGnSJAsWLMhpp52W8ePH11l3/Pjx+cEPfpD58+encePGOfHEE+tjSAAAAADQoJrUR6dbbbVVzj///Py///f/8v7776dv377p1q1b9t9//3To0CFJ8tFHH+Uf//hHRo0alaVLl6asrCw//OEPs+2229bHkAAAAACgQdVLEJckZ511VmbPnp1BgwZl6dKlef755/P888+vVG/p0qVJkv79++ecc86pr+EAAAAAQIOql1tTq1122WW5/fbb07Vr15SVlWXp0qU1vsrKyvKNb3wjgwYNyo9//OP6HAoAAAAANKh6WxFX7aCDDspBBx2UuXPn5vXXX8/MmTOTJO3atcvuu++eVq1a1fcQAAAAAKDB1XsQV61Vq1Y54IADino4AAAAANig1OutqQAAAADAMoI4AAAAACiAIA4AAAAACiCIAwAAAIACCOIAAAAAoACCOAAAAAAogCAOAAAAAAogiAMAAACAAgjiAAAAAKAAgjgAAAAAKIAgDgAAAAAKIIgDAAAAgAII4gAAAACgAII4AAAAACiAIA4AAAAACiCIAwAAAIACCOIAAAAAoACCOAAAAAAogCAOAAAAAAogiAMAAACAAgjiAAAAAKAAgjgAAAAAKIAgDgAAAAAKIIgDAAAAgAII4gAAAACgAII4AAAAACiAIA4AAAAACiCIAwAAAIACCOIAAAAAoACCOAAAAAAogCAOAAAAAAogiAMAAACAAgjiAAAAAKAAgjgAAAAAKIAgDgAAAAAKIIgDAAAAgAII4gAAAACgAII4AAAAACiAIA4AAAAACiCIAwAAAIACCOIAAAAAoABNGnoA9WHp0qV5991389prr5W+JkyYkKqqqiTJ8OHDs80229TZfvDgwbniiitW+zi77LJLHn744VXWmTlzZv74xz/mySefzNSpU1NeXp4ddtghRx99dE488cQ0abJR/hMAAAAAsIKNMgWaMmVKjjjiiIYeRl5//fWceeaZqaioKP1s4cKFGTNmTMaMGZOhQ4fmtttuy2abbdaAowQAAACgCBtlELe8jh075utf/3pmzZqVl19+ea3bv/LKK3WWNW7cuM6y2bNn5+yzz05FRUVatWqVK664It27d8+nn36aBx98MLfcckvGjBmTiy++OLfeeutajwsAAACAL5aNMohr06ZN/vCHP2TPPfdM+/btkyQ33HDDOgVxLVq0WKcx3HrrrZk+fXrKyspy0003pWvXrqWyiy66KM2bN891112XkSNHZuTIkenRo8c6PQ4AAAAAXwwb5WENLVu2TK9evUohXNEWL16c+++/P0lyyCGH1AjhqvXv3z9t2rRJktx9992Fjg8AAACA4m2UQVxDe/nllzN37twkSe/evWutU15enl69eiVJnn/++Xz66aeFjQ8AAACA4gni1lBlZeUa1x03blzpeq+99qqzXnXZokWL8vbbb6/74AAAAADY4G2Ue8StT8cdd1zeeuutVFVVZdNNN83uu++eb33rWznhhBOy6aab1tpm4sSJSZJGjRqlU6dOdfa9zTbb1Gjzta99bf0OHgAAAIANhhVxq/H666+nqqoqSbJgwYK8/PLLGTBgQPr06ZPx48fX2mbWrFlJklatWqVp06Z19t2uXbvS9ezZs9fjqAEAAADY0FgRV4vmzZvnuOOOS69evbLTTjulY8eO+eyzzzJ+/PjcfffdGTZsWCZNmpT+/ftn8ODB2XLLLWu0X7hwYZKkWbNmq32cagsWLFj/T+T/b968eRk9enS99b829t1334YeAsBqbShz5obMfA58EZjPV898DnwRbEzzuSCuFkcccUSOOOKIlX7etWvXdO3aNXvssUcGDBiQGTNm5LrrrsuAAQMaYJQAAAAAfJEI4tbBqaeemmHDhuW1117LY489lquuuqrGLaibbLJJkmWHMKzK8iel1rXf3PrQsmXLdO7cud76B9jYWB0AsHEwnwNsHDa0+XzChAmZN2/eOrW1R9w66tmzZ5Jlt5S+//77Ncratm2bJJk7d24WL15cZx8zZ84sXbdp06YeRgkAAADAhkIQt44233zz0vXcuXNrlO2www5JkiVLlmTKlCl19jF58uSV2gAAAACwcRLEraOKiorSdatWrWqUdenSpXQ9duzYOvsYM2ZMkmWHOuy8887reYQAAAAAbEgEceto+PDhSZIWLVrkK1/5So2yrl27lsK5xx57rNb2lZWVGTFiRJLkwAMPrHGCKgAAAAAbH0HcCubNm7faDfcGDhyYcePGJUl69+5d46CGJGnSpElOOOGEJMlTTz1V6zG7gwYNKu0Rd9JJJ62PoQMAAACwAdtoT019++23awRq06ZNK12/8cYbmTFjRun77bbbLu3atUuSTJo0KaecckqOOOKI9OjRI7vssktat26dysrKjB8/Pvfcc09pNVz79u3zox/9qNbHP+OMMzJ06NBMnz4955xzTq644op07949n376af7yl79k4MCBSZIePXqkR48e6/35AwAAALBh2WiDuF/84hd58cUXay0777zzanw/YMCA9O3bt/T93Llzc++99+bee++ts/+dd945119/fbbccstay9u0aZObb745Z555ZioqKnL55ZevVGevvfbK7373uzV5OgAAAAB8wW20Qdy62m677XL11VdnzJgxef311zNjxozMnj07jRo1Srt27dKlS5f06tUrRxxxRMrLy1fZ1+67754hQ4Zk0KBBGT58eKZOnZqmTZtmxx13zNFHH50TTzwxTZr4JwAAAAD4MihbunTp0oYeBPVjwoQJmTdvXlq2bJnOnTs39HBq2PGhiQ09BICVvHvcDg09hC+c90b5nQEbnu27ea+5tt670nwObHi2/8WGOZ9/nrzFYQ0AAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAGaNPQA6sPSpUvz7rvv5rXXXit9TZgwIVVVVUmS4cOHZ5tttlltP4sXL869996boUOHZuLEiamsrEynTp3Sq1evnHrqqWnXrt1q+5g5c2b++Mc/5sknn8zUqVNTe4pGiQAAIABJREFUXl6eHXbYIUcffXROPPHENGmyUf4TAAAAALCCjTIFmjJlSo444ojP1ccnn3yS/v37Z+zYsTV+/s477+Sdd97J4MGDc+utt2a33Xars4/XX389Z555ZioqKko/W7hwYcaMGZMxY8Zk6NChue2227LZZpt9rrECAAAAsOHb6G9N7dixY771rW+la9eua9Xu4osvztixY1NWVpazzz47f/vb3/Lss89mwIAB2WyzzVJRUZGzzjors2fPrrX97Nmzc/bZZ6eioiKtWrXKgAED8uyzz+Zvf/tbzj777JSVlWXMmDG5+OKL18fTBAAAAGADt1EGcW3atMkf/vCHPPfcc3nmmWfy+9//PgcccMAat3/mmWcycuTIJMkFF1yQiy66KNttt106dOiQvn375uabb05ZWVmmT5+e2267rdY+br311kyfPj1lZWW56aab0rdv33To0CHbbbddLrroolxwwQVJkpEjR5YeCwAAAICN10YZxLVs2TK9evVK+/bt16n93XffnSRp27Zt+vfvv1J5165dc8ghhyRJHnjggSxevLhG+eLFi3P//fcnSQ455JBaV+P1798/bdq0qfF4AAAAAGy8Nsog7vP49NNPM2rUqCTJoYcemvLy8lrr9e7dO8myW1BHjx5do+zll1/O3Llza9RbUXl5eXr16pUkef755/Ppp5+ul/EDAAAAsGESxK3grbfeyqJFi5Ike+21V531li8bN25cjbLlv1+TPhYtWpS33357ncYLAAAAwBeDIG4FEydOLF1vs802ddbr1KlTGjVqtFKb5b9v1KhROnXqVGcfy/e/Yh8AAAAAbFwEcSuYNWtW6XrzzTevs17Tpk3TqlWrJFnp5NTqPlq1apWmTZvW2Ue7du1K13WdvgoAAADAxqFJQw9gQ7Nw4cLSdbNmzVZZt7p8wYIFtfaxuvbNmzcvXa/Yx/o0b968lfaxayj77rtvQw8BYLU2lDlzQ2Y+B74IzOerZz4Hvgg2pvncijgAAAAAKIAVcSvYZJNNStfVhzbUpbp80003rbWP1bVf/qTUFftYn1q2bJnOnTvXW/8AGxurAwA2DuZzgI3DhjafT5gwIfPmzVuntlbEraBt27al648//rjOelVVVZk7d26SpE2bNrX2MXfu3CxevLjOPmbOnFm6XrEPAAAAADYugrgV7LDDDqXryZMn11lv6tSpWbJkyUptlv9+yZIlmTJlSp19LN//in0AAAAAsHERxK1gl112KR2yMHbs2DrrjRkzpnTdpUuXGmXLf78mfTRr1iw777zzOo0XAAAAgC8GQdwKmjdvnm7duiVJhg8fnsrKylrrPfbYY0mW3VK64r3KXbt2TatWrWrUW1FlZWVGjBiRJDnwwANrnKAKAAAAwMZHEFeLk046KcmyPdwGDRq0Uvno0aPz9NNPJ0mOP/74NGlS88yLJk2a5IQTTkiSPPXUU7Ueszto0KDSHnHVjwcAAADAxmujPTX17bffrnGCxbRp00rXb7zxRmbMmFH6frvttku7du1K3x988MHp0aNHRo4cmeuuuy4LFy7Md77znTRv3jzPPfdcBgwYkCVLlmTLLbfM6aefXuvjn3HGGRk6dGimT5+ec845J1dccUW6d++eTz/9NH/5y18ycODAJEmPHj3So0eP9f30AQAAANjAlC1dunRpQw+iPvTr1y8vvvjiGtUdMGBA+vbtW+Nnc+fOzemnn17nHm/t27fPrbfemt12263Ofl9//fWceeaZqaioqLV8r732ym233ZbNNttsjca5tqqP023ZsmU6d+5cL4+xrnZ8aGJDDwFgJe8e5+CctfXeKL8zYMOzfTfvNdfWe1eaz4ENz/a/2DDn88+Tt2y0K+I+r1atWuXuu+/OvffemyFDhmTixImpqqpKp06dcuihh+a0006rsYquNrvvvnuGDBmSQYMGZfjw4Zk6dWqaNm2aHXfcMUcffXROPPHElW5rBQAAAGDjtNGuiMOKOIC1ZUXc2rMiDtgQWRG39qyIAzZEG+OKOIc1AAAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAGaNPQANkSTJ0/OoYceukZ1R40alXbt2tVatnjx4tx7770ZOnRoJk6cmMrKynTq1Cm9evXKqaeeWmc7AAAAADY+grh68sknn6R///4ZO3ZsjZ+/8847eeeddzJ48ODceuut2W233RpohAAAAAAUSRC3GgMHDkzXrl3rLG/RokWtP7/44oszduzYlJWV5ayzzsp3vvOdNG/ePM8991x+/etfp6KiImeddVaGDBmSNm3a1NfwAQAAANhA2CNuNZo3b54WLVrU+VWbZ555JiNHjkySXHDBBbnooouy3XbbpUOHDunbt29uvvnmlJWVZfr06bntttuKfDoAAAAANBBBXD24++67kyRt27ZN//79Vyrv2rVrDjnkkCTJAw88kMWLFxc5PAAAAAAagCBuPfv0008zatSoJMmhhx6a8vLyWuv17t07STJ79uyMHj26sPEBAAAA0DAEcWuosrJyjeq99dZbWbRoUZJkr732qrPe8mXjxo37fIMDAAAAYIPnsIbV+OUvf5kpU6ZkwYIFKS8vz/bbb59/+7d/yymnnJKOHTuuVH/ixIml62222abOfjt16pRGjRplyZIlNdoAAAAAsHGyIm413nrrrSxYsCDJslVxb775Zm6//fb07t07w4YNW6n+rFmzStebb755nf02bdo0rVq1SrLs9lQAAAAANm5WxNWiUaNG6d69e4488sh06dIlW221VZo1a5b3338/w4YNy3//939nwYIF+fGPf5zWrVune/fupbYLFy4sXTdr1myVj1NdXh301Zd58+ZtMPvQ7bvvvg09BIDV2lDmzA2Z+Rz4IjCfr575HPgi2Jjmc0FcLTp16pTbb799pZ/vuuuu2XXXXXPwwQfn1FNPzaJFi/LLX/4yjzzySBo3btwAIwUAAADgi0IQtw722Wef9OvXL7fddlvee++9vPbaa9l7772TJJtsskmpXvWhDXWpLt90003rb7BJWrZsmc6dO9frYwBsTKwOANg4mM8BNg4b2nw+YcKEzJs3b53a2iNuHfXs2bN0/frrr5eu27ZtW7r++OOP62xfVVWVuXPnJknatGlTDyMEAAAAYEMiiFtHyx/E8Mknn5Sud9hhh9L15MmT62w/derULFmyZKU2AAAAAGycBHHraMaMGaXrzTbbrHS9yy67lA5hGDt2bJ3tx4wZU7ru0qVLPYwQAAAAgA2JIG4d/e1vfytdLx+kNW/ePN26dUuSDB8+PJWVlbW2f+yxx5Isuy11Q7vXGQAAAID1TxBXi2nTpq2y/B//+EfuvvvuJMn222+fPfbYo0b5SSedlCSZOXNmBg0atFL70aNH5+mnn06SHH/88WnSxJkZAAAAABs7CVAtjj322Oy333459NBD06VLl2yxxRZJkkmTJmXYsGG56667UlVVlSZNmuQ///M/06hRzTzz4IMPTo8ePTJy5Mhcd911WbhwYb7zne+kefPmee655zJgwIAsWbIkW265ZU4//fSGeIoAAAAAFEwQV4vFixfniSeeyBNPPFFnndatW+dXv/pVDjrooFrLr7322px++ukZO3Zsbrrpptx00001ytu3b59bbrnFiakAAAAAXxKCuFoMGDAgL7/8csaOHZvp06dn9uzZqaqqSuvWrbPzzjune/fu+e53v5u2bdvW2UerVq1y99135957782QIUMyceLEVFVVpVOnTjn00ENz2mmnpV27dgU+KwAAAAAakiCuFt/61rfyrW9963P306RJk5x88sk5+eST18OoAAAAAPgic1gDAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAAAAQAEEcQAAAABQAEEcAAAAABRAEAcAAAAABRDEAQAAAEABBHEAAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFKBJQw/gy+Kpp57Kvffem3HjxmXOnDnZYost0q1bt3z/+99P586dG3p4AAAAANQzK+IKcOWVV+bss8/O008/nYqKilRWVmbq1Kl58MEH893vfjd//etfG3qIAAAAANQzQVw9u/XWW3PvvfcmSXr16pXBgwdn1KhRuf3227PrrrumsrIyP/3pTzN69OgGHikAAAAA9UkQV49mzpyZG2+8MUnSvXv3/P73v0+XLl3Srl27dO/ePX/605+yxRZbZPHixfnNb37TwKMFAAAAoD4J4urRQw89lAULFiRJLr744pSVldUob9u2bU4//fQkydixYzNu3LjCxwgAAABAMQRx9eipp55Kkmy33Xbp0qVLrXV69+5duh4xYkQh4wIAAACgeIK4elS9wm3PPfess07Hjh2z5ZZb1qgPAAAAwMZHEFdPpk+fXrotddttt11l3W222SZJMnHixHofFwAAAAANQxBXT2bNmlW63nzzzVdZt7p89uzZ9TomAAAAABpOk4YewMaqejVckjRr1myVdavL58+fv17HsGjRoiTJvHnzMnr06PXa97pq2bJlkuTR3Rt4IAC1mDBhQpJl8yarVj2fp91jDTsQgFqYz9dcaT4/yXwObHg29Pm8OndZG4K4jdhnn33W0ENYyYb6Pw8Aa8d8DrBxMJ8DrLt1yV0EcfVk0003LV2vLiGtLm/RosV6HUOzZs2yaNGiNG7ceLWr8gAAAABYvUWLFuWzzz5bp6xFEFdP2rZtW7r++OOPV1m3urxNmzbrdQy77+7+TwAAAIANhcMa6kmHDh1Kq+ImTZq0yrqTJ09Okuywww71Pi4AAAAAGoYgrp6UlZWlS5cuSZLXXnutznrTpk3L9OnTk6RUHwAAAICNjyCuHn3zm99Mkrz//vt54403aq3z2GP/ezpRz549CxkXAAAAAMUTxNWj4447rnR76rXXXpulS5fWKJ89e3Zuu+22JMmee+5pRRwAAADARkwQV4/atWuXc889N0ny7LPP5kc/+lHeeOONzJw5M3//+9/Tr1+/VFRUpEmTJrnssssaeLQAAAAA1KeypSsu02K9u/LKK3PvvffWWta0adNcffXVOfbYYwseFQAAAABFEsQV5Kmnnso999yTcePGZc6cOWnfvn0OOOCAnHrqqencuXNDDw8AAACAeiaIAwAAAIAC2CMOAAAAAAogiAMAAACAAgjiAAAAAKAAgjgAAAAAKIAgDgAAAAAKIIgDAAAAgAII4gAAAACgAII4AAAAACiAIA42coMHD07nzp1LX3/961/XuP7kyZMLGuWG5x//+IffA/CFZe6vf8v/zgDWpxXn8Oqv3XbbLd/4xjfy3e9+N7/73e8yffr0hh5qkuTyyy9P586d069fv8/VT8+ePdO5c+fccMMN62lksGESxMGXzI033pjPPvusoYfRYNbXGwWAL5Iv+tzfr1+/dO7cOZdffnlDDwWgwSxZsiRz5szJP//5z9xyyy054ogj8vTTTzf0sFbJh9uwMkEcfMm8//77q10ZAcDGxdwP8MU0cODAvPLKK3nllVcyevToPPzwwzn99NPTqFGjzJs3LxdeeGE++OCDhh4msBYEcfAlsu222yZZtjKiqqqqgUezYdt///0zYcKETJgwIdtss01DDwdgnZn7Ab64mjdvnhYtWqRFixZp2bJldtlll/z4xz/OD3/4wyTJwoULM2jQoAYd4zXXXJMJEybkzjvv/Fz9jBgxIhMmTMj555+/nkYGGyZBHHyJVL9gT548OYMHD27g0QBQBHM/wMbnjDPOSLNmzZIko0aNauDRAGujSUMPACjOfvvtlwMOOCAvvPBCbr755hx33HEpLy9f637mzJmTu+66K0899VQ++OCDzJ8/P+3atUvXrl3Tr1+/7L333qtsP378+Nxyyy156aWXMmfOnLRv3z49evTIGWecka233rq08fWAAQPSt2/fGm0XLVqUUaNGZcSIEXn11VczefLkVFVVpXXr1tl9993Tp0+fHHnkkWnUqObnDIMHD84VV1xR+v7FF19caYPt4447Ltdcc02SZftZnHLKKUmS4cOHl1bF3XXXXbnqqqvSqFGjPP3009lyyy3rfJ4vvfRSTj755CTJf//3f+eggw5aqc6oUaPyl7/8Ja+88kpmzJiR8vLybL/99vn2t7+dk08+OZtuuukqf5cAq9PQc3+/fv3y4osv1phja1Pb3H/DDTfk97//fanOQw89lIceeqhGu/POO6+0eqK6/tZbb50RI0bk7bffzqBBgzJq1Kh89NFHad68eV5++eUkydKlS/Paa69lxIgRGTVqVN57773Mnz8/LVq0yI477piePXvmpJNOSsuWLdf6dwVQ35o1a5btttsub731VqZNm1ajbPLkyfnjH/+Y5557rlS21VZb5aCDDsppp52Wrbfeus5+33zzzdx555156aWXMm3atHz22Wdp27Zttthii+yzzz459NBD061btxptLr/88jz00EP5xje+UWNV3IrvtQ899NCVHm/ChAml6549e2bKlCk15vU5c+ake/fuqayszMUXX5yzzjprlb+XXr16ZdKkSTnqqKNy7bXXrlQ+ffr03HnnnXn22WczZcqULFq0KB06dMj++++fH/zgB9l5551X2T+sD1bEwZfMBRdckCSZOnVqHnjggbVu/8ILL+Swww7L9ddfn9deey2zZ89OVVVVpk+fnmHDhuXEE0/M9ddfX2f7IUOG5Dvf+U4eeeSRVFRUpLKyMlOmTMk999yTvn375l//+tcqH//aa6/NWWedlfvuuy9vvvlmFixYkKqqqsyYMSMjR47MpZdemrPPPjuVlZVr/dzWxBFHHJGmTZtmyZIlGTp06CrrVpe3b99+pTcsixYtyiWXXJJTTz01Dz/8cKZOnZrKysrMmzcv//rXv3LttdemT58+ee+99+rleQBfLg099zeEJ598Mn379s1f/vKXTJkyZaXbcocPH54TTjghN998c8aOHZs5c+Zk8eLFmTNnTl599dVce+216du3byZNmtRAzwBg1ao/eF66dGnpZ8OGDUvv3r1z5513ZuLEiVm4cGEWLlyYd999N3feeWd69+6dRx99tNb+hg0bluOOOy73339/qW1lZWWmT5+ecePG5c4778yvfvWrQp5btdatW+eQQw5JktW+93711VdLc3afPn1WKh82bFgOO+yw3HrrrRk/fnw++eSTVFZWZvLkyXnwwQfTp0+f3H///ev9OcCKrIiDL5l99tkn3bt3z3PPPZdbbrklxx9//BqvjBg3blzOOOOMVFZWZvfdd88ZZ5yRvfbaKy1atMikSZNy1113ZfDgwbnxxhvTqVOnHH/88TXajx8/PldccUUWL16cLbfcMpdcckkpoBo1alT+7//9v7nwwgtXOYbNNtssJ5xwQg488MBsu+22ad++fRo1apQPP/wwjz76aO6+++4888wzue666/KTn/yk1K5Pnz759re/nSuvvDJDhw7Nvvvum1tvvbVG302bNl3t76Bt27b5t3/7t4wYMSJDhgzJ6aefXmu9ysrKPPbYY0mSo446aqUVej/+8Y/z+OOPp2nTpunXr1+OPPLIbLPNNvn000/zwgsv5LrrrsukSZNy9tlnZ/DgwVbGAZ9LQ879n8dZZ52VH/zgBznjjDMyevToHH300fnFL35Ro05tc/ecOXPyk5/8JNttt11+9KMfZe+9986SJUvyz3/+s1SnSZMm6dmzZ3r27JmddtopHTp0SIsWLfLRRx9l1KhRGTRoUN5///1cfPHF6xReAtSnqqqq0iENHTp0SJK8/PLLufTSS7NkyZJ06tQpF198cfbff/8kyz5QufbaazNt2rRccskl6dixY42VzHPnzs1//Md/ZPHixenSpUvOOeecfPWrX03r1q0zf/78TJw4MS+88ELGjRu3xmN85ZVX8vLLL+fMM89MsiwI22qrrdb6ufbp0ydPPPFE3nrrrbz++uvZfffda603ZMiQJMnmm2++0p0oTz31VC655JIsXbo0+++/f0499dR06dIlzZo1y9tvv53bbrstTz31VP7zP/8zW2+9da13ssD6IoiDL6ELLrggzz33XKZPn5577rkn3//+99eo3RVXXJHKysrstddeufPOO2v8Ede6desMGDAg7du3zy233JLf/e53Ofroo9O8efNSnd/+9rdZvHhxWrZsmbvuuqu0gXiSHHPMMdlrr71y7LHHrnIMdW3e2r59++yxxx7p1q1bzjjjjNxzzz0599xzS7cUNWnSpPSVJI0bN06LFi3W6Hmv6JhjjiltJvvmm29m1113XanOyJEjM2fOnFL95T3xxBN5/PHHU1ZWluuvv36lZfrHHntsDjjggBx33HGZOHFi7rnnnvTv33+dxgpQraHm/s+jvLw85eXlady4cZJlc/mazN3z5s3L9ttvn3vuuSebbbZZ6efLbydwyCGHlFZZLK9t27bp3LlzjjjiiBx11FF57bXXMmrUqJVWNgM0pDvuuCMLFy5MklLY9stf/jJLlixJu3btcs8996Rjx46l+n369EnXrl3Tt2/fzJo1K7/85S9r7Bv68ssvZ8GCBWncuHFuv/32tG3btlTWqlWrbLXVVjnwwAPXaowtWrSo8XpQffDE2jr44IPTpk2bzJ49O0OGDKk1iFu8eHFppd+RRx5Zes+fLLsT5ac//WmWLl2ab3/727n++utTVlZWKu/atWu6du2aSy65JA8//HCuueaa1a6+g8/DranwJbTHHnvkm9/8ZpLk1ltvzaeffrraNi+88EJpD4df//rXda6kOPfcc7Pppptm5syZee6550o//+ijj/L3v/89ybL9gpYP4ap95StfSb9+/db6+SyvR48eadeuXRYsWJBXX331c/VVl549e5b+sKv+5G1F1T/fZZddsttuu9Uo+9Of/pQk6d27d617ZSRJx44d873vfS/J6pfhA6yJhpj7G9IFF1xQI4RbWx06dCiFb88///z6GhbAOluyZEk+/PDD3HTTTbnuuuuSLFsVfOqpp+af//xnxo8fnyQ555xzaoRw1Tp16pSzzz47ybLVzsuvbvvss8+SLAvLWrduXd9PZa2Ul5fn29/+dpJlq+qWLFmyUp1nn302s2bNSrLybakPP/xwPv7445SXl+dXv/pVjRBueZdcckmSZfvkVf8uoT4I4uBL6kc/+lHKyspSUVGRu+++e7X1q09j6tSpUzp27Jj58+fX+vXZZ59lhx12SJIa+72NHTu2tH9Fz54963ycuoKp5c2cOTM33XRTTjrppBxwwAHp0qVLOnfuXPqaOXNmktTb/mrl5eU5/PDDkyx7YV9+X44k+eSTT/LUU08lWfmNwMKFCzNmzJgkyz69rOv3OH/+/NJKuwkTJtTbnnfAl0vRc39DKSsrS48ePVZbr6qqKg888EDOPPPM9OjRI3vssUeN15PqLQbs1wk0lFNOOaU0J+2222455JBDct1116Wqqirl5eUZMGBAdt5554wePbrUpvp9am2WL6s+vCZJvvrVr6asrCzz58/PT3/605UOgGho1XeYfPTRR3nhhRdWKq/+4HrHHXfM17/+9Rpl1R+mfP3rX0+jRo3qfC1r3bp1aSXg8lsZwPrm1lT4ktp9993Tq1ev/O1vf8ttt92WE088cZX7kE2cODHJso2+99lnnzV6jOpALEmmTJlSut5xxx3rbLOqsmTZG4Yf/vCHmT179mof/5NPPlmDUa6bPn365IEHHsiHH36YF198sXRLQJI89thjqaysTFlZWY4++uga7SZNmlTaMPzKK6/MlVdeudrHWrJkSel0WYDPo+i5v6G0bdt2taedVlRU5Ac/+EHefPPN1fZXn68nAGujSZMm2XbbbdOtW7f069ev9N556tSpSZbdRlq9Z1xtOnbsmM022yyffPJJqU2SbLvttjnllFNyxx13ZPDgwXnooYfSuXPndO3aNfvuu28OPPDAtGnTpn6f3Cq8zu9sAAAgAElEQVTsu+++2WabbTJ58uQMGTKkxm2y8+bNy4gRI5Jkpffeyf++lo0ePXqNX8uqV9dBfbAiDr7Ezj///JSVleXjjz/On//851XWXZc/QpZfxbVgwYLS9SabbFJnm1X9QfjJJ5/kvPPOy+zZs7P55pvn0ksvzf33359nn302o0ePziuvvJJXXnmltAls9RL7+rDffvuVjn5f8fbU6k/k9ttvv5U2pF3XP+YWLVq0Tu0AVlTk3N9QVvU6U+0nP/lJ3nzzzdJtXX/84x8zYsSIvPjii6XXk6OOOipJ/b6eAKzKwIEDS3PSmDFjMm7cuDz22GO58sora3yAPX/+/CSrfi9drbpOdZtqV1xxRa6++ursuuuuWbp0acaPH58///nPueiii9K9e/dceuml+eijj9bjs1s71XeaPPHEEzW2V3jyySezcOHClJWV1Xpa6rx589b6sbz3pj5ZEQdfYp07d87hhx+eRx99NLfffntOOumkOutWv2Dvscce63R63PJvChYuXFjnSoXlA7sVPfbYY5k1a1YaNWqUP/3pT9l5551rrbcuL7Zrq6ysLEcddVRuueWWPP7447nyyitTXl6eadOm5aWXXkpS+7Hpy29QO3DgwBx88MH1PlaA5RU596+pxYsX11vftfnggw9Ktyr9x3/8R0488cRa61VvhA7QUNb0gIPqOqt6L12tus6K/ZaVleX444/P8ccfn2nTpuWVV17J6NGj89RTT2XKlCkZOnRoXnnllfzP//zP59qDc1316dMnN954Y+bPn5/hw4fnyCOPTPK/H4rvs88+2WabbVZqV/1a1rt379LeetCQrIiDL7nzzz8/jRo1yuzZs0uHCNSm+nCFSZMmrbQn2pro1KlT6bp6eXhtVlVWvWF4586d6wzhPvzww8JuIareq2L5PeEefvjhLFmyJM2aNat1f46tt946jRotm3onTZpUyDgBVlTU3J8kzZo1S5JVHg5R9AqL5Tfhrv5DrjZrctsqwIag+k6NuXPnrnJOnT59eum9cnWb2nTs2DFHHHFEfvazn2X48OH5yU9+kmTZdjMPPvjgehz5mtthhx2yxx57JPnfO1AqKipKe8bV9iF48r+vZR988EEBo4TVE8TBl9xOO+1U+iNk0KBBdYZYBx10UJJl+yXUtkHq6uy1116lE4qq93CozfDhw+ssq77daVW3CK3uhNHqo8zXx21GO+20U7p06ZLkfz+Jq/7vIYccUusnhZtttlnpDcQjjzzyuccAsC6KmvuTlPa3XNUHLc8+++wq+1ifc3dS8/bZuvocM2aMD0yAL4x99923dP3EE0/UWa/6EJoV26xKWVlZ+vfvX3pv++67767xuKrn7yS1nna6tqrDtueeey4zZ87MsGHD8tlnn6Vp06bp3bt3rW2qX8veeOMNh++wQRDEATnvvPPSuHHjzJ07t879grp37146xfPnP/95ZsyYsco+J0+eXOMPnQ4dOpQ2Vb3zzjszefLkldpMmjQpd955Z519Vi81nzhxYt5///2Vyt95553cfPPNqxxX9Saz62v1RfWbgWeeeSYvvfRSadVe9Wq52px22mlJlm0YO2jQoFX2/9lnn9X6XAE+ryLm/iTZc889kyxbhbb8SrRqM2bMyB/+8IdV9ru+5+7lb12qXtG8vPnz5+cXv/jFenksgCJ87Wtfy1e/+tUkyU033ZTp06evVGfatGml98pdunQpfaCcLHsfvqo9PmfMmFHaU25tDm1Yvu76mMOPPPLINGnSJFVVVXn00UdrfAjeunXrWtscc8wx2XzzzbNkyZJcfvnlK+2Nt6J33nnnc48TVkUQB2T77bcvBUd1LdkuKyvLNddck+bNm+e9997LMccck9tvvz1vvvlm5syZk48//jhvvPFGHnjggZx99tk57LDDVtqr7dJLL03jxo3zySef5OSTT87QoUNTUVGRioqKDBkyJCeffHLatWtX5zgPO+ywNGrUKFVVVTnzzDMzfPjwVFRUZOrUqbn77rvzve99L5tssskq3xxUv+GYNGlS7rrrrnz88cdZvHhxFi9evE6f0h111FFp3LhxqqqqctlllyVZ9oajR48edbY5/PDDSytRrrnmmvzwhz/MM888k+nTp2fu3LmZMmVKRo4cmd/+9rfp1atX7rjjjrUeF8DqFDX3H3744aV9iM4999wMHz48s2bNyvTp0/M///M/OeGEE0q3r9aleu4ePXp0Hn300cyePftzzd1f//rXS2Hc1VdfnbvuuiuTJk3Kxx9/nOHDh+fEE0/M+PHjs8MOO6x13wAN5Wc/+1kaNWqUGTNm5N///d8zbNiwVFRU5KOPPsrQoUPz7//+75k5c2YaN26cn/3sZzXa/vWvf803v/nNXH311Xn66aczefLkzJ07N5MnT86jjz6aU089NUuWLEmjRo3qXHlWm6985SulvaEHDhyYiRMnZtGiRaU5fG21a9cu3bt3T5LcfvvtGTduXJK6b0tNlh3gM2DAgDRq1Civvvpqjj322Nxzzz159913M3fu3FRUVOS1117Ln//85/Tr1y/f/e5313pcsDYc1gAkWfbH0dChQ1NVVVVnnS5dumTQoEG58MILM3369PzXf/1X/uu//qvWuo0bN07jxo1r/Gz33XfPr3/96/x//9//lw8//DCXXnppjfLWrVvnhhtuyPHHH1/qY3nbb799Lrzwwvzud7/Le++9l3PPPbdG+WabbZYbbrghl112WWbPnl3ruL75zW9m2223zaRJk3LVVVflqquuKpUdd9xxueaaa+p8/rXZYostcuCBB+bZZ5/NlClTkizbCLZp06arbHfNNdekZcuWue+++/Lkk0/mySefrLPu6voCWFdFzP1t2rTJz3/+81x22WWZMmXKSnP3lltumYEDB65yr7ZjjjkmAwcOzJw5c3LhhRfWKDvvvPNy/vnnr+6prjTOX/3qVznzzDMzb968Gq8FSdKoUaNcdtllGT9+/CpvqQXYkHTt2jW//e1vc8UVV2TKlCm5+OKLV6rTrFmz/OY3v8nee++9UtmMGTNy55131nmHSuPGjfPTn/40u+222xqPqUmTJvne976XW265Jc8880yeeeaZGuXVd5OsjWOOOSZPP/106b13q1atcsghh6yyzcEHH5zf//73ufzyy/PBBx/k5z//eZ1161pZB+uLIA5IsmwT0759++a+++5bZb199tknjz/+eB588MGMGDEiEyZMyJw5c9K4ceNsscUW2WWXXdKtW7ccfvjhtb6IHXvssdl1111zyy235KWXXsrcuXPTvn37dO/ePWeeeWbatm1bqlvbCVFnnXVWdtppp9xxxx0ZN25cFi9enC233DIHHXRQ+vfvX9qMtS7NmzfPXXfdlRtvvDGjRo3KtGnTPvfx5Mccc0yN/Y1W9YlctfLy8lx11VX5P//n/+S+++7Lyy+/XBpLy5Yts+2222avvfbKIYccUrqlF2B9K2ru79OnT7baaqsMHDgwr732WhYsWJCOHTumV69eOeOMM1a5GjpZts/cvffem5tvvjkvvfRSKioqVhkerokDDjgg999/f2688ca8+OKLmTdvXtq2bZu99947/fr1y3777ZfLL7/8cz0GQNGOOuqo7Lnnnrnjjjvy3HPPZdq0aUmWHb7QvXv3nHbaabUe0vD9738/u+yyS0aNGpV//etf+eijjzJr1qw0bdo0W2+9db7xjW/kpJNOqvPAtFW58MILs+WWW2bIkCF5++23M3/+/HU+AChJevbsmZYtW5ZWYB9++OEpLy9fbbtDDz00Tz75ZO67776MHDkyb7/9dj755JOUl5enQ4cO+epXv5qDDjoohx122DqPDdZE2dLP838AwHr2+uuv57jjjkuSPPjgg/na177WwCMCAACA9cMeccAGpfpE1fLy8tIG4QAAALAxEMQBhapr77Ykee+990qniPbs2XONlpgDAADAF4U94oBC/eQnP0mLFi1y5JFHpkuXLmnRokUqKiry7LPP5uabb868efPStGnTlTbzBgAAgC86QRxQqM8++yyPPPJIHnnkkVrLy8vL85vf/CadO3cueGQAAABQvxzWABRqzJgxefzxx/PSSy9l+vTpmTVrVsrLy9OpU6d069Ytp5xyympPPgUAAIAvIkEcAAAAABTAYQ0AAAAAUABBHAAAAAAUQBAHAAAAAAUQxAEAAABAAQRxAAAAAFAAQRwAAAAAFEAQBwAAAAAFEMQBAKxGv3790rlz5/Ts2bOhh8IG7vLLL0/nzp3TuXPnhh4KALABatLQAwAANh6T/3/t3XlQ02f+B/A3QjiDICh4YEt1PSpIUYmEqtUKiOOBiMeutuiudfGodqvY2dp1x+72AK1rXY/RVktRdDxqEZW6XAUPGK4KKiLWM1pSF8QQyxUlgd8fTL6TkBDlCu1v368ZZ8L3+X6fPN+Q7wzz9vM8T1kZAgMDjbZZWVlBLBbDw8MDo0ePxty5cxlW/D/09OlTpKSkIDU1FSUlJaiqqsKTJ09gb28PNzc3eHp6wtvbG/7+/njllVdgZcU/R4mIiOh/B//yISIiIrNQq9VQKpVQKpW4evUqDh48iMjISKxZs6a7h0ad5Pr161izZg3u3Llj0FZdXY3q6mrcvn0b33//PQBg69atmD59urmH2Sa64fKqVauwevXqbh7Rb9v777+PEydOAAB+/PHHbh4NERGR+TGIIyIioi7h7e2N6Oho4WeVSoWysjIkJycjJSUFjY2N2LNnD3r37o2IiIhuHOmzxcfHd/cQfvXkcjkWL14MpVIJAPD19UVoaCiGDRsGBwcH1NbWQiaToaioCGfPnkVlZWU3j7hrxMTEICYmpruHQURERL9SDOKIiIioS9jb22Po0KF6x3x8fDBt2jQcOXIEGzduBADs2rULCxcuhKWlZXcMkzrJ1q1bhRAuMjISUVFRBuf4+flh7ty5aGxsRGZmJtzd3c09TCIiIqJuxc0aiIiIyOx+//vfw8PDAwBQVVWFkpKSbh4RdYRGoxGmm7q6uuLdd981eX6PHj0QGBgIb29vcwyPiIiI6FeDFXFERERkdhYWFvDy8kJZWRkA4Oeff4aPj0+r5xcWFiIhIQEFBQV4+PAh1Go1evfujVGjRmH+/Pnw9/c3uGbfvn347LPPAABfffUVxo8fb3JMOTk5+OMf/wgAiIqKQmRkpNAWERGB/Px8DBgwABkZGSb7OXfuHJKSklBUVCRMv3R3d4efnx/eeOMNjBgxwuCas2fPYtmyZQCA3bt3G92d9fPPP8eePXsANFcWfvPNNwbn1NTUwN/fH2q1GosXL8YHH3yg1y6Xy3Ho0CHk5ubi/v37qK+vh1gshrOzMzw8PBAQEICgoCB4enqavMeWFAoF6uvrAQAeHh6dVt1YW1uLY8eO4ezZs7h9+zaUSiUcHBzw0ksvYdKkSVi4cCF69uxp9NqEhASsX78eAHDgwAH4+/sjPT0dR44cQWlpKR4/fgw3Nze8+uqrWLZsGQYOHGjQR8vNRHbu3ImdO3fqHWv5nXjWGmgt2+vr6xEfH4///Oc/uH//Pnr06IHBgwcjIiJCb/08tVqNxMREJCQk4M6dO6ivr8eLL76I2bNnIyIi4rk2vWjPc6Q1efJkyOVyjB07FvHx8aisrERcXBzS09Px4MEDiEQiDBkyBHPmzEF4eDh69ND///4dO3YYfHbGNmuJjo5GeHi48HNdXR2OHj2KjIwM3Lp1C9XV1bC2toazszPc3NwgkUgwceJE+Pn5PfP+iYiIfg0YxBEREVG30A1rWgtuVCoVNmzYgNOnTxu0yeVyyOVyJCUlISwsDB999BGsra2F9pkzZ2Lr1q3QaDRITEx8ZhCXmJgIoLlaKzQ0tM33o1QqsXbtWmRnZxu0yWQyyGQyHD9+HJGRkVi7di0sLCyEdj8/P1hZWUGtViM3N9doEJeTkyO8LikpQU1NDcRisd45P/zwA9RqNQBAKpXqtaWnpyMqKgoqlcpg3EqlEjKZDFlZWbh79y4++eSTNt277ud+7949NDQ0QCQStamPlnJychAVFYVHjx4ZjLeoqAhFRUXYv38/tm/fDolEYrKvxsZGrF+/HgkJCXrH5XI5vvnmGyQnJyM2NtZkGNwVysvL8dZbb+HmzZt6x7X3d/XqVfz1r3/FL7/8gnfeeUfvOwA0B3kxMTHIz8/Hrl27DMIvrY48R8ZcunQJb7/9tt46fyqVCoWFhSgsLEROTg7+9a9/Pe/H0CqZTIYlS5ZALpfrHW9oaEBtbS3kcjmKioqQnJyMtLS0Dr8fERGROTCIIyIiom5x69Yt4bV2mqoujUaDZcuWITc3FwAQEBCAmTNnwsPDAw4ODrh79y6OHTuG/Px8JCYmokePHnqbQ7i7uyMgIABZWVlIT09HbW0tHBwcjI6lvr4eqampAAB/f3/07du3TfdSW1uLN998Ezdv3oSFhQWmTJmCwMBAeHh4QCQS4ccff8ShQ4dQWlqKL7/8EjY2Nli1apVwvVgshre3Ny5duiTcr66amhq96bsajQb5+fkGgZ32WktLS4wdO1Y4/ujRI7z33ntQqVSws7PDvHnzMG7cOLi6uqKpqQkVFRUoKSnB2bNn23TfWk5OThgwYADkcjmUSiX++c9/YsOGDbCxsWlXf9nZ2YiMjIRarYazszMWLFgAb29v9O3bFzU1NcjJycHBgwehUCgQGRmJY8eOYciQIa32t337dhQWFmLSpEkIDw+Hh4cHlEolEhISkJSUhOrqaqxbtw5nzpzRqyw7ffo0Kioq8NZbbwEAFixYgIULF+r13ZHA8Z133sH9+/exZMkSTJw4EWKxGNeuXcP27dvx8OFDxMbGYtKkSYiLi0NeXh7mzZuHkJAQuLi44O7du9ixYwdkMhkyMjLw7bffYt68eQbv0dHnqKWKigqsWLECTU1NWLNmDfz8/GBra4vi4mLs2rULDx8+RFJSEsaNG6dX2bZw4UKEhIRg27ZtwjRmY8Gg7rP33nvvCSHc1KlTERISgr59+8LW1hYKhQI3btxAdna2QVBHRET0a8YgjoiIiMwuKysLN27cAAAMGjQIw4cPNzhn3759yM3NhUgkwrZt2xAUFKTX7u3tjZkzZyI6OhpxcXFISEjAnDlz9KaohYWFISsrC/X19UhJSdELBnSlpqairq5OuKatNm3ahJs3b8LR0RF79+7FqFGj9Np9fHwwe/ZsREVFITk5Gbt378asWbP0pkNKpVJcunQJN27cgEKhgIuLi9BWUFAAtVoNOzs7jBkzBllZWUYr5/Ly8gAAXl5eetVymZmZwv1t2bLF4LMEgKCgIPzlL39BVVVVm+8fABYvXoxPP/0UAHDs2DGkpqbi9ddfx+jRo+Hl5YUhQ4Y8s9IKaA4d161bB7VajYCAAOzcudOg8k8qlWL27NlYsGABFAoFPvnkE8TFxbXaZ2FhIVatWoXVq1frHR83bhysra2RkJCAe/fu4dy5cwgMDBTahw4dCnt7e+FnV1dXgw1IOqKkpARxcXF631lvb2+MHDkS4eHhaGxsxLvvvguFQoHPP/8c06ZNE87z8vKCRCLB1KlTUVdXh0OHDhkN4jrjOdIlk8nQr18/HD58GP369dPrRyqVIjQ0FE+fPkV8fLze8+bq6gpXV1e9qcSmPsuffvoJV65cAQCj06wBYPz48ViyZEm7v7NERETdgZs1EBERkVk8efIEt27dws6dO4VqMJFIhPXr1+tN0wSaK9RiY2MBNK/PZiw40oqKikKfPn0AwGDdtODgYKEKTjv11JhTp04BaN7pdcqUKW26r//+97/ClMc1a9YYhHBaVlZW+PDDDyESiaBWq4V1wrS0U0mbmpqEQE1LW800ZswYYYpty2mKSqUS169f1+tLS3cKYcu2lnr16mWyvTWLFi3SqxZTKpU4ceIE/v73vyM8PBxjxozBwoUL8dVXX0GhULTaz+HDh6FQKGBnZ4etW7cahHBanp6eePvttwE0fxY//fRTq32OGDFCrwJR19KlS4XXBQUFJu+xs0VERBgNvF5++WWMHj0aQPP6eyEhIXohnJa7uzuCg4MBANevX0dNTY1ee2c9Ry1t2LBBL4TTeumll4Qgs7S01GA8bfHw4UPhtam164D2f2eJiIi6A4M4IiIi6hL5+fkYNmyY8M/HxwfTp0/Hjh07UF9fj6FDh2LPnj147bXXDK4tKCiAUqkE0LzWmynW1tZCaFFYWKjXZmtri5CQEGE8Dx48MLi+oqJCCLWmTJmiVwH1PDIzM9HQ0AAAeovrG9OrVy+hCqjlWEePHi1UjLWcnqr92d/fXwjSbt68qRdo5efno7GxEYBh2KY73e9ZIUt7WVhYYOPGjTh48CACAwMNpmw+ffoUFy9exObNmxEYGIj4+Hij/WjX+goICNCrCjRGd/pty89T18yZMw3CXq3BgwcLv3NTYV5XmDFjRqttL7/8cpvOa2pqEjY/0eqs50iXWCw2uoah1siRI1sdT1vofmcTExOFZ4yIiOi3jlNTiYiIyOxEIhHCw8Nb3UBBOyUNAGbPnv3c/epW0WiFhYUhISEBTU1NOHnyJJYvX67XfurUKWg0GuHcttId67Mqd0yN1cbGBr6+vsjPz9cL4qqqqoTdNwMCAjB8+HA4OztDqVQiNzdXqJTSVtGJRCKMGTNGr+/AwEC4uLhAoVAgJiYGp06dQlBQEPz8/AymsXaURCKBRCJBXV0dLl++jOLiYly7dg2FhYUoLy8H0LwT5scff4za2lq934dGoxHWwsvIyDC6q2ZrjP3utQYNGmTyWicnJ9TV1XWogqs9TI3L0dGxzee1HH9nPkdanp6erW4KATR/lq2Npy369++PcePGITs7G6mpqQgKCkJISAj8/f0xcuRIuLm5tbtvIiKi7sSKOCIiIuoS3t7eOH36tPDvwIEDeP/999G/f380NDQgJiYGmzZtMnqtqamLptTX1xscGzt2LAYMGAAAOHnypEG79li/fv3aFKRpdeZYtZVsMplMCK3y8vLQ1NSEnj17wsvLCxYWFkIlmG5gp33t6+sLW1tbvX4dHR2xb98+eHp6AoCwIcCiRYswduxYzJ07F/v27cMvv/zSrnsxxt7eHgEBAYiMjMS2bdtw/vx5HDx4EN7e3sI5O3fu1Fto//Hjx8Kur23VcjdYXXZ2diav1QZL2opCczE1Lt2wq+Xvs7XztIGyVmd+N7WeVTFqajxttWXLFkyYMAFA8xTw/fv3Y+XKlZgwYQKmTJmCTZs24d69ex16DyIiInNjRRwRERF1CXt7e4PF2P39/REeHo4FCxbg9u3biI2NhVQqxcSJE/XO0w1jYmNjhbWr2sPCwgKhoaHYvXs37ty5gytXrsDHxwdA8zpW2k0jQkNDTVb6tEY7VgsLC5w8ebLVKZAtGdttUyqVYvv27QCa1z0LCwsTAjaJRCKMTyqVIjU1VWirrKwUdqFtbQ04Ly8vnDlzBufOnUNmZiYuXryIO3fuQKPRoLi4GMXFxdi7dy+2bduGgICANnwCz08ikWD//v0IDQ2FXC5HQ0MD0tPTsXjxYgD6wY1284jn5erq2unj/a3rzOeoO7i4uGDfvn24cuUKUlJSUFBQgGvXrqGhoQH37t1DbGwsDhw4gHXr1uFPf/pTdw+XiIjouTCIIyIiIrNycnLCli1bMGfOHDQ2NuLTTz/Fq6++qhdM6a4N5ujo2OGdKsPCwrB7924AzRVw2iBOt0Ju1qxZ7epbO9ampib06dPnmeuameLj4wN7e3vU1dUhLy9PL4jTDdi0r+/du4cHDx7orellajMGS0tLTJ48WVjjq6qqCnl5eThx4gTOnj0LpVKJ1atXIz09Hc7Ozu2+D1PEYjFmzpyJPXv2AGiu/tNydnaGhYUFmpqa0NDQ0Kk7lP4v6uznqLv4+PgIz6xKpUJRURGSk5ORkJCAp0+fIiYmBsOHD++yAJmIiKgzcWoqERERmd2IESOE4EsmkxlsIKA7ffGHH37o8Pt5enrC19cXAPDdd9+hoaEBGo0GSUlJAJoXmB88eHC7+vby8hJed3TXTd313fLy8lBeXo67d+8C0A/YBg8eLFQ35eTkCGGdnZ0dXnnlled+v169emHq1Kn44osvhB1Pq6urcf78+Q7dx7PoLsSvW0EoEomEdeEuX778q1ig/3krHH+NOvs56gwd/TxtbW0REBCAf/zjH9i8ebNw/Lvvvuvo0IiIiMyCQRwRERF1i5UrV8LKqrk4/4svvsDTp0+FNqlUKmwgcOjQIZNrVj0v7UYMVVVVOHfuHLKzs4VF6duzSYNWYGAgLC0tAQBff/11h9cZ0wZucrlcCCh79+5tdJov0Lw2nDaIGzNmjNEpr89Dd+OM9q4t9ryuXr0qvH7hhRf02oKDgwEASqUSx48f79JxPA/d9dl0v6O/BV3xHHWUjY2N8Lqjn6d2/Tig67+zREREnYVBHBEREXWLF154AaGhoQCaF2LXrYoTi8VYsmQJAKCsrAxr165FXV2dyf6ys7Nx8eLFVtunTZsGa2trAM1TUrXTUkUiEaZPn97u+xg4cKAQ5BUVFeHDDz80ueFAY2MjkpOThTXdWtKtfIuLiwNgfDdW7XkZGRm4f/9+q+cBwPnz5/HgwQOT93HhwgXh9cCBA02e21JtbS3mzp2LtLS0Z262cO7cOSQmJgJoniobGBio175o0SJhWmxMTIzeuIxRKBSIj49v03jbwsnJSfje6E6j/S3oiueoo3R3O9VWexpTWlqK4uJik33pVm629TtLRETUXbhGHBEREXWbFStW4OTJk9BoNPjyyy8xb948IfRYvnw5CgsLkZWVhYyMDEydOhXz58/H6NGj0atXL6hUKjx48ADFxcVIT0/H/fv38fHHHwtTO1tycnLC66+/jpSUFGRmZgpVbBMnTkSvXr06dB9/+9vfcO3aNZSWluLo0aPIy8vDvHnzMHLkSPTs2RN1da9Cy4AAAATtSURBVHUoKyvD5cuXkZaWhoqKCnz99df43e9+Z9DXiBEj4OTkhMePH6O6uhqA8XXftMe057R2HgCcOXMGp06dgkQiwfjx4zFs2DC4uLhArVbj559/xpkzZ5CWlgageRqvbqXR8youLsaqVavg4uKCyZMnw9fXFy+++CJ69uwJlUoFmUyG77//HmlpaWhqagIALF261CBA6dmzJ/79739j6dKlUKlU+POf/4ygoCAEBwfD09MTIpEIjx8/xo0bN5Cbm4sLFy7AxcUFERERbR7z87CysoKvry/y8/ORmZmJuLg4SCQSoVJOJBIZVPX9mnT2c9RRfn5+wuuPPvoIy5cvR9++fYUpq25ubnB0dERpaSnWr1+PoUOHYvLkyfDy8oK7uzssLS1RWVmJrKwsHD16FABgbW2N+fPnd8l4iYiIOhuDOCIiIuo22qq4EydOCFVxb7zxBoDmaqndu3cjOjoaR44cQXl5OXbs2NFqXxYWFnBwcDD5frNmzUJKSgoaGhqE9cc6Mi1Vy8HBAQcPHsQHH3yAlJQUyGQyfPbZZ62eb2lpCTs7O6NtPXr0gEQiQXp6unDMWMA2cOBADBgwAHK5HEDzYvy669W1pNFo9KaxGuPp6Yk9e/YIYejzsrKyQp8+ffDw4UMoFAocP37c5LRSkUiE5cuXY9WqVUbbpVIp4uPjERUVBblcjrS0NCEoNMbR0bFN422rlStX4uLFi2hoaEB0dLRe24ABA5CRkdGl798RXfEcdYREIoG/vz/y8vJQUFBgsK5idHQ0wsPDhZ9v3Lgh7GxsjFgsxubNm9u9xiMREZG5MYgjIiKibrVixQqcOnXKaFWctbU1Nm7ciDfffBPHjx9Hfn4+ysrKUF1dDRsbG/Tu3RuDBw+Gv78/goKCnjk97bXXXoOLi4uwnpSzszMmTpzYKfchFouxfft2XLlyBYmJiSgoKEB5eTlqampga2sLd3d3DBkyBFKpFMHBwcJmC8ZIpVIhiOvfv3+rFVdSqRTffvstgOaAQ1vl19L69esxYcIE5OXl4fr166isrMSjR4+g0Wjg4uKCYcOGITg4GGFhYW0O4YDmdb8uXLiAK1euIDc3F5cuXcLdu3dRUVEBlUoFGxsbODk5Cb+rGTNmoH///ib7HDVqFFJSUpCUlISMjAyUlJRAoVBArVZDLBZj4MCBGDlyJMaPH9+uCr62CAgIwOHDh7F//35cunQJlZWVePLkSZe+Z2fq7OeoIywsLLB3717s378f6enpkMlkqKmpgUaj0TtvxowZcHNzQ05ODoqLi1FeXo7KykqoVCqIxWIMGjQI48ePxx/+8Ae4urp22XiJiIg6m0WTdm4AERERERERERERdRlu1kBERERERERERGQGDOKIiIiIiIiIiIjMgEEcERERERERERGRGTCIIyIiIiIiIiIiMgMGcURERERERERERGbAII6IiIiIiIiIiMgMGMQRERERERERERGZAYM4IiIiIiIiIiIiM2AQR0REREREREREZAYM4oiIiIiIiIiIiMyAQRwREREREREREZEZMIgjIiIiIiIiIiIyAwZxREREREREREREZsAgjoiIiIiIiIiIyAwYxBEREREREREREZkBgzgiIiIiIiIiIiIzYBBHRERERERERERkBgziiIiIiIiIiIiIzIBBHBERERERERERkRn8H90qE+3y0YNtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 625,
              "height": 381
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSS9Tvi-JAr_"
      },
      "source": [
        "## Data Preprocessing - Tokenizing, Padding & Attention Mask\n",
        "\n",
        "### What is a tokenizer ? \n",
        "\n",
        "* The tokenizer is in-charge for preparing inputs to the model\n",
        "* Tokenizing(splitting the words into sub-words token string), converting tokens into strings to ids & back and encoding/decoding ie (tokenizing and converting into integers)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svKRn6PJK_pk"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHLVZej6_qDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "10ee41241f214245a4880b90f26dea13",
            "072500071e9643ad9a0818385d91806e",
            "34ebbfb33d9549c79693804ed79ff2e8",
            "2ae4492b69e14adeb01863d3a69655ac",
            "20e14b670b1848c3b560b6965c0af6aa",
            "7fd2ea1d12ab4ec98543016b9ef750ae",
            "32ee6b56d44a4b8fae4ec80242735e00",
            "cc854791c5b743f19234150f9262ac7f"
          ]
        },
        "outputId": "9bc97e08-07d3-4692-bf23-d2b0feeaf7a4"
      },
      "source": [
        "### Downloading the pre-trained tokenizer\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10ee41241f214245a4880b90f26dea13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNc41axhk2vM"
      },
      "source": [
        "## Let's see how the tokenizer is working on the sample sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYJCADaJvJO"
      },
      "source": [
        "sample_text = 'When was I last outside? I am stuck at home for 8 months.'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Giv-DKuQlYHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a083cb17-cc83-4f5a-ba69-2bab802a9b9e"
      },
      "source": [
        "### Getting tokens from the tokenizer\n",
        "tokens = tokenizer.tokenize(sample_text)\n",
        "print(tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '8', 'months', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXkcJ6gQl2mB"
      },
      "source": [
        "* As mentioned in the above points the **tokenizer converts the sentences into tokens** and these **tokens are then converted into ID's**(integers) & then these ID's are then passed into the BERT model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_TZdknlhvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c919c76e-f127-45b0-d8ea-b7764225bbb5"
      },
      "source": [
        "### Converting the tokens into ID's(integers)\n",
        "\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 129, 1808, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaNUiDSVmtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4abb0b8-600e-4546-fd22-d9ee68a7ee54"
      },
      "source": [
        "print(\"The length of the tokens is : \", len(tokens))\n",
        "print(\"The length of the token ID's are : \", len(token_ids))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the tokens is :  15\n",
            "The length of the token ID's are :  15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOhawsqwnQr9"
      },
      "source": [
        "* We can see that the length of the tokens and token ID's is the same.\n",
        "* To be more precise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN_jTo4RnMo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5891ca-da92-49c8-b550-2f868960c363"
      },
      "source": [
        "print(f'Sentence : {sample_text}')\n",
        "print(f'Tokens : {tokens}')\n",
        "print(f'Token IDs : {token_ids}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence : When was I last outside? I am stuck at home for 8 months.\n",
            "Tokens : ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '8', 'months', '.']\n",
            "Token IDs : [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 129, 1808, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPUGPJ3_20Bk"
      },
      "source": [
        "### What is mask ?\n",
        "* If your input sentence is smaller than the max length, it's the mask that we use for attention when we have a varying length sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp1gbPuWnwju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f44d15-4c01-4be6-93db-df45a118f82f"
      },
      "source": [
        "encodings = tokenizer.encode_plus(\n",
        "    sample_text,\n",
        "    max_length = 32,\n",
        "    add_special_tokens = True,\n",
        "    pad_to_max_length = True,\n",
        "    return_attention_mask = True,\n",
        "    return_token_type_ids = False,\n",
        "    return_tensors = 'pt'\n",
        ")\n",
        "encodings.keys()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-gZ6qC20UuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7d0b71-be5d-40b4-908b-f05869ac5ee9"
      },
      "source": [
        "encodings['input_ids']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "         1111,  129, 1808,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNfAeMLD2rq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30188166-c7fc-461d-bbc7-2e3d6aeb9535"
      },
      "source": [
        "print(\"The length of the input ID's is : \", len(encodings['input_ids'][0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the input ID's is :  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gsIAR8i6-Sl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e969e793-410f-4380-cc40-2d08bbadff4a"
      },
      "source": [
        "print(encodings['attention_mask'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N9esOSH7L2G"
      },
      "source": [
        "* In above we can see that **1's** are the tokens and 0's are the paddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qO8G2zL8QA7"
      },
      "source": [
        "### Choosing The Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOS7_pd57K4q"
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df.content:\n",
        "  tokens = tokenizer.encode(txt, max_length = 512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysn08vkr8uL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "062c37be-23cf-4837-9af6-f81ecb795a9a"
      },
      "source": [
        "sns.distplot(token_lens)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4c478e9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 637,
              "height": 363
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Zitp24-siZ"
      },
      "source": [
        "### Creating a PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hsbfyV680-K"
      },
      "source": [
        "class ASReviewDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, review, target, tokenizer, max_len):\n",
        "    self.review = review\n",
        "    self.target = target\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.review) ## Returns the no. of reviews\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.review[item])\n",
        "\n",
        "    encodings = tokenizer.encode_plus(\n",
        "      review,\n",
        "      max_length = self.max_len,\n",
        "      add_special_tokens = True,\n",
        "      pad_to_max_length = True,\n",
        "      return_attention_mask = True,\n",
        "      return_token_type_ids = False,\n",
        "      return_tensors = 'pt'\n",
        "    )\n",
        "    return{\n",
        "        'input_ids' : encodings['input_ids'].flatten(),\n",
        "        'attention_mask' : encodings['attention_mask'].flatten(),\n",
        "        'targets' : torch.tensor(self.target[item], dtype=torch.long)\n",
        "    }\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skWS-2PwKgp1"
      },
      "source": [
        "MAX_LEN = 160\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69_RV5IzNxLL"
      },
      "source": [
        "### Train Test Splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnF2Sg1uNq4t"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gANbSLUUOtzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70410e27-7c02-49ae-97b9-7a322a8d8fba"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((960, 13), (120, 13), (120, 13))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dUwXmBcPDZB"
      },
      "source": [
        "### Wrapping all this into PyTorch Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6bwaLqBO7GL"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = ASReviewDataset(\n",
        "      review = df.content.to_numpy(),\n",
        "      target = df.sentiment.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "      ds,\n",
        "      batch_size = batch_size,\n",
        "      num_workers = 4\n",
        "  )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXPuNfHYQZeH"
      },
      "source": [
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGFdDrVXA9Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8723d3-8dc1-4bc1-8301-1543a8b179e8"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUu65j9JEsGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67582ff8-772d-40e9-cf17-caefac370c8b"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4rPvul4MXiN"
      },
      "source": [
        "### What is BERT ?\n",
        "* BERT stands for Bidirectional Encoder Representation from Transformers.\n",
        "* When we just stack just the layers of Encoders we get BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-aXOJnYJb3p"
      },
      "source": [
        "### Creating the BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVPtzGw_I8yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "cb5c28404742467daf5b30106a7bb340",
            "6408b1cb5df746f4843a7533a8ed81ac",
            "1274a36953ec4263ba3e1e08fe45b36d",
            "42a95d6e5d8e4b9c8ed965f67cd74165",
            "dd36be0668ed418ab637bff2d62dc62d",
            "4ebf5225668346b48fbad03d9dba32e8",
            "a686fae296584a32983598c058056fcf",
            "9b6842ab2dbe492ebb7a903fcc1c5b48",
            "dab436ba23ac40babb8ccf644b9b5c3f",
            "62ad8288bd1541c3bea4b9a6057e3053",
            "326756cd1bea461da68e73cab6c65760",
            "79e9132152724a9a929768a8460c3d12",
            "a3a267f7e2a1440cb1da8bd99ccd9b12",
            "fa5f4830b6da4ca29f8481295e42ba17",
            "bf45c973cfed4775b8099c7ad90777b7",
            "34550bb0d1d04df3b3133abede4214ef"
          ]
        },
        "outputId": "94edf346-4be1-403e-bb3c-0df12647aeb9"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5c28404742467daf5b30106a7bb340",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab436ba23ac40babb8ccf644b9b5c3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWuUhzzW73Fd"
      },
      "source": [
        "### Calling our bert_model\n",
        "\n",
        "last_hidden_state, pooled_output = bert_model(input_ids = encodings['input_ids'], \n",
        "                                              attention_mask = encodings['attention_mask'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0iAqrRf9DJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a6c842-171a-448e-86b3-d3e3e331818e"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYSazrZA9N87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77f31e6-6d29-44e6-d9e9-820dd9d00f16"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMhGHa1t9qv5"
      },
      "source": [
        "### Building our Sentiment Classifier using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbfTjAb29Vp6"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME) ## Calling our BERT model\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes) ## output layer\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZsY7bpXAEz9"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRlHAAK-CvsT"
      },
      "source": [
        "### We are going to have a look at sample data from the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZlbRI_-AVD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a41f899-c394-4093-dbda-07bdffa5143d"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDdxhIpqDQFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11529c4-b55c-4225-cc85-5084a0e7c667"
      },
      "source": [
        "model(input_ids, attention_mask)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8213, -0.2035,  0.7903],\n",
              "        [ 0.3952, -0.9701, -0.0532],\n",
              "        [ 0.2649, -0.2759,  0.9315],\n",
              "        [ 0.9355, -0.6754,  0.3680],\n",
              "        [ 0.7902, -0.4404, -0.0749],\n",
              "        [ 0.0471, -0.5883,  0.4140],\n",
              "        [ 0.4517, -0.8235,  0.4320],\n",
              "        [-0.0027, -0.0331,  0.3492],\n",
              "        [ 0.3690, -0.3712,  0.8212],\n",
              "        [-0.0391, -0.0549,  0.7573],\n",
              "        [ 0.3442, -0.4971,  0.3261],\n",
              "        [ 0.8131,  0.0751,  0.7585],\n",
              "        [ 0.6459, -1.2998,  0.1575],\n",
              "        [ 0.1790, -0.8513, -0.0388],\n",
              "        [ 0.5980, -0.2476,  0.6000],\n",
              "        [ 0.3651, -0.2827,  0.5078]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnMdo5_vE4C"
      },
      "source": [
        "## Training our Model\n",
        "\n",
        "* In this the optimizer which we will be using is **AdamW** which is the combination of **Adam optimizer** & **weight decay**\n",
        "\n",
        "#### What is weight decay ?\n",
        "* **After** each **weight** **update**, the **weights** are **multiplied** by the **factor** **slightly** **less** **than** **1**.\n",
        "* This **prevent** the **weights** from **growing** too large & can be seen as gradient descent on quadratic regularization terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdTAoTuCFPxU"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps\n",
        ")\n",
        "## Loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9kbjGLka6NM"
      },
      "source": [
        "### Defining a Training Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcN__e6HZDt2"
      },
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUX0ak2mcij7"
      },
      "source": [
        "### Evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIKbI94Yceoh"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9xgRfdIdHcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df3aabe-b65e-4ad7-f6ed-3a607707d993"
      },
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 1.0689066777626672 accuracy 0.4354166666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.951023206114769 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.8488329748312632 accuracy 0.603125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.0188461244106293 accuracy 0.5166666666666666\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.6673600008090337 accuracy 0.715625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.2144675329327583 accuracy 0.44166666666666665\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.5208433578411739 accuracy 0.796875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.5238442718982697 accuracy 0.525\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.3644074040154616 accuracy 0.8614583333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 1.705254688858986 accuracy 0.5166666666666666\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.26234614408264556 accuracy 0.9083333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.360672205686569 accuracy 0.525\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.19875758333752552 accuracy 0.9291666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.8388904333114624 accuracy 0.48333333333333334\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1642477000520254 accuracy 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.6831948459148407 accuracy 0.5333333333333333\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1278558765305206 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.8592656701803207 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1184610107409147 accuracy 0.9552083333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 2.9388697147369385 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.12705981256149243 accuracy 0.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.3315856754779816 accuracy 0.475\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.11304951387962016 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.0026627480983734 accuracy 0.5416666666666666\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1168170923992875 accuracy 0.9552083333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.3922663033008575 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1017480884140241 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.147758826613426 accuracy 0.5\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.10194103281197991 accuracy 0.9520833333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.182854190468788 accuracy 0.5\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1015552730706986 accuracy 0.9541666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.2545957416296005 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09377426877132772 accuracy 0.9614583333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.344730466604233 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09613115883451731 accuracy 0.9510416666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.2391624599695206 accuracy 0.5\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09188680438722562 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.305189788341522 accuracy 0.5\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09178569683208479 accuracy 0.9572916666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.409245103597641 accuracy 0.5\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09295216942409752 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.3275868743658066 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09346114954726849 accuracy 0.9572916666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.404058560729027 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09564320501255376 accuracy 0.9572916666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.321183428168297 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09452984462138071 accuracy 0.9604166666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.4391797930002213 accuracy 0.5\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09113662402402649 accuracy 0.9604166666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.4443981647491455 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09552667159756917 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.4578551650047302 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09333633780382418 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.461989641189575 accuracy 0.5\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09506096574720384 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.5100307166576385 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09128608168054295 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.5984448194503784 accuracy 0.5166666666666666\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09420415331769619 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.565630465745926 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0878425930403561 accuracy 0.9614583333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.5986249297857285 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08920031274853196 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.655684858560562 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0884311455648761 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6495265513658524 accuracy 0.5\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08620604083334911 accuracy 0.9552083333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6934452652931213 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08349546692212849 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6336370557546616 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09288089418817738 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.576686352491379 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0857752725367997 accuracy 0.9604166666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.645612895488739 accuracy 0.5\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08993612147399593 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6170167326927185 accuracy 0.5\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08716771103499923 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.625093713402748 accuracy 0.5\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09605553069874682 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.619346722960472 accuracy 0.5\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09001291771273827 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6346085220575333 accuracy 0.5\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.09101425676914611 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6473853439092636 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0919168438068785 accuracy 0.9572916666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.6879271119832993 accuracy 0.5\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08600020867330992 accuracy 0.9583333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.696726933121681 accuracy 0.49166666666666664\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08819237364914442 accuracy 0.9572916666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.745138704776764 accuracy 0.5083333333333333\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08408998465311016 accuracy 0.959375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.75329452753067 accuracy 0.5\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08698725199477243 accuracy 0.959375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.7544377744197845 accuracy 0.5\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08965949581991785 accuracy 0.953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.754861131310463 accuracy 0.5\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08941260757940957 accuracy 0.9541666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.7574492394924164 accuracy 0.5\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0883587647365251 accuracy 0.9562499999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 3.754952073097229 accuracy 0.5\n",
            "\n",
            "CPU times: user 15min 29s, sys: 9min 46s, total: 25min 15s\n",
            "Wall time: 25min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm8eAqwOeEWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "16d90cc6-990e-4892-bdf6-374cd4a1dbd6"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 620,
              "height": 398
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkhKLbTrXEQf"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}